{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenRouterComponent",
            "id": "OpenRouterComponent-a2foO",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "agent_llm",
            "id": "Agent-zHygU",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenRouterComponent-a2foO{œdataTypeœ:œOpenRouterComponentœ,œidœ:œOpenRouterComponent-a2foOœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-Agent-zHygU{œfieldNameœ:œagent_llmœ,œidœ:œAgent-zHygUœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenRouterComponent-a2foO",
        "sourceHandle": "{œdataTypeœ:œOpenRouterComponentœ,œidœ:œOpenRouterComponent-a2foOœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "Agent-zHygU",
        "targetHandle": "{œfieldNameœ:œagent_llmœ,œidœ:œAgent-zHygUœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ComposioRedditAPIComponent",
            "id": "ComposioRedditAPIComponent-Y34v6",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-zHygU",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ComposioRedditAPIComponent-Y34v6{œdataTypeœ:œComposioRedditAPIComponentœ,œidœ:œComposioRedditAPIComponent-Y34v6œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-zHygU{œfieldNameœ:œtoolsœ,œidœ:œAgent-zHygUœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ComposioRedditAPIComponent-Y34v6",
        "sourceHandle": "{œdataTypeœ:œComposioRedditAPIComponentœ,œidœ:œComposioRedditAPIComponent-Y34v6œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-zHygU",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-zHygUœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-zHygU",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-eoS4K",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__Agent-zHygU{œdataTypeœ:œAgentœ,œidœ:œAgent-zHygUœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-eoS4K{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-eoS4Kœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Agent-zHygU",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-zHygUœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-eoS4K",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-eoS4Kœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-HBnme",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenRouterComponent-a2foO",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ChatInput-HBnme{œdataTypeœ:œChatInputœ,œidœ:œChatInput-HBnmeœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-OpenRouterComponent-a2foO{œfieldNameœ:œinput_valueœ,œidœ:œOpenRouterComponent-a2foOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-HBnme",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-HBnmeœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenRouterComponent-a2foO",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenRouterComponent-a2foOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "Agent-zHygU",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "https://docs.langflow.org/agents",
            "edited": false,
            "field_order": [
              "agent_llm",
              "api_key",
              "base_url",
              "project_id",
              "max_output_tokens",
              "max_tokens",
              "model_kwargs",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "context_id",
              "n_messages",
              "format_instructions",
              "output_schema",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "last_updated": "2026-01-20T03:39:39.959Z",
            "legacy": false,
            "lf_version": "1.7.2",
            "metadata": {
              "code_hash": "fba2d73636e5",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_core",
                    "version": "0.3.83"
                  },
                  {
                    "name": "pydantic",
                    "version": "2.11.10"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.models_and_agents.agent.AgentComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "group_outputs": false,
                "loop_types": null,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "input_types": [],
                "value": "f3b41284-a194-4443-91b5-8f1157eb27d3"
              },
              "_frontend_node_folder_id": {
                "input_types": [],
                "value": "5abc5f52-5ec3-4b44-b9b2-c1fb69504bf7"
              },
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Language Model",
                "dynamic": false,
                "external_options": {
                  "fields": {
                    "data": {
                      "node": {
                        "display_name": "Connect other models",
                        "icon": "CornerDownLeft",
                        "name": "connect_other_models"
                      }
                    }
                  }
                },
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [
                  "LanguageModel"
                ],
                "name": "agent_llm",
                "options": [
                  "Anthropic",
                  "Google Generative AI",
                  "OpenAI",
                  "IBM watsonx.ai",
                  "Ollama"
                ],
                "options_metadata": [
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "WatsonxAI"
                  },
                  {
                    "icon": "Ollama"
                  }
                ],
                "override_skip": false,
                "placeholder": "Awaiting model input.",
                "real_time_refresh": true,
                "refresh_button": false,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport re\n\nfrom langchain_core.tools import StructuredTool, Tool\nfrom pydantic import ValidationError\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.base.agents.events import ExceptionWithMessageError\nfrom lfx.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODEL_PROVIDERS_LIST,\n    MODELS_METADATA,\n)\nfrom lfx.base.models.model_utils import get_model_name\nfrom lfx.components.helpers import CurrentDateComponent\nfrom lfx.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom lfx.components.models_and_agents.memory import MemoryComponent\nfrom lfx.custom.custom_component.component import get_component_toolkit\nfrom lfx.custom.utils import update_component_build_config\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.inputs.inputs import BoolInput, SecretStrInput, StrInput\nfrom lfx.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    documentation: str = \"https://docs.langflow.org/agents\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    # Filter out json_mode from OpenAI inputs since we handle structured output differently\n    if \"OpenAI\" in MODEL_PROVIDERS_DICT:\n        openai_inputs_filtered = [\n            input_field\n            for input_field in MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"]\n            if not (hasattr(input_field, \"name\") and input_field.name == \"json_mode\")\n        ]\n    else:\n        openai_inputs_filtered = []\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*MODEL_PROVIDERS_LIST],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            refresh_button=False,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST if key in MODELS_METADATA],\n            external_options={\n                \"fields\": {\n                    \"data\": {\n                        \"node\": {\n                            \"name\": \"connect_other_models\",\n                            \"display_name\": \"Connect other models\",\n                            \"icon\": \"CornerDownLeft\",\n                        }\n                    }\n                },\n            },\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            info=\"The API key to use for the model.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            info=\"The base URL of the API.\",\n            required=True,\n            show=False,\n        ),\n        StrInput(\n            name=\"project_id\",\n            display_name=\"Project ID\",\n            info=\"The project ID of the model.\",\n            required=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n            show=False,\n        ),\n        *openai_inputs_filtered,\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Chat History Messages\",\n            value=100,\n            info=\"Number of chat history messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MultilineInput(\n            name=\"format_instructions\",\n            display_name=\"Output Format Instructions\",\n            info=\"Generic Template for structured output formatting. Valid only with Structured response.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=(\n                \"Schema Validation: Define the structure and data types for structured output. \"\n                \"No validation if no output schema.\"\n            ),\n            advanced=True,\n            required=False,\n            value=[],\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n        ),\n        *LCToolsAgentComponent.get_base_inputs(),\n        # removed memory inputs from agent component\n        # *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [\n        Output(name=\"response\", display_name=\"Response\", method=\"message_response\"),\n    ]\n\n    async def get_agent_requirements(self):\n        \"\"\"Get the agent requirements for the agent.\"\"\"\n        llm_model, display_name = await self.get_llm()\n        if llm_model is None:\n            msg = \"No language model selected. Please choose a model to proceed.\"\n            raise ValueError(msg)\n        self.model_name = get_model_name(llm_model, display_name=display_name)\n\n        # Get memory data\n        self.chat_history = await self.get_memory_data()\n        await logger.adebug(f\"Retrieved {len(self.chat_history)} chat history messages\")\n        if isinstance(self.chat_history, Message):\n            self.chat_history = [self.chat_history]\n\n        # Add current date tool if enabled\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n\n            if not isinstance(current_date_tool, StructuredTool):\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise TypeError(msg)\n            self.tools.append(current_date_tool)\n\n        # Set shared callbacks for tracing the tools used by the agent\n        self.set_tools_callbacks(self.tools, self._get_shared_callbacks())\n\n        return llm_model, self.chat_history, self.tools\n\n    async def message_response(self) -> Message:\n        try:\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            result = await self.run_agent(agent)\n\n            # Store result for potential JSON output\n            self._agent_result = result\n\n        except (ValueError, TypeError, KeyError) as e:\n            await logger.aerror(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            await logger.aerror(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        # Avoid catching blind Exception; let truly unexpected exceptions propagate\n        except Exception as e:\n            await logger.aerror(f\"Unexpected error: {e!s}\")\n            raise\n        else:\n            return result\n\n    def _preprocess_schema(self, schema):\n        \"\"\"Preprocess schema to ensure correct data types for build_model_from_schema.\"\"\"\n        processed_schema = []\n        for field in schema:\n            processed_field = {\n                \"name\": str(field.get(\"name\", \"field\")),\n                \"type\": str(field.get(\"type\", \"str\")),\n                \"description\": str(field.get(\"description\", \"\")),\n                \"multiple\": field.get(\"multiple\", False),\n            }\n            # Ensure multiple is handled correctly\n            if isinstance(processed_field[\"multiple\"], str):\n                processed_field[\"multiple\"] = processed_field[\"multiple\"].lower() in [\n                    \"true\",\n                    \"1\",\n                    \"t\",\n                    \"y\",\n                    \"yes\",\n                ]\n            processed_schema.append(processed_field)\n        return processed_schema\n\n    async def build_structured_output_base(self, content: str):\n        \"\"\"Build structured output with optional BaseModel validation.\"\"\"\n        json_pattern = r\"\\{.*\\}\"\n        schema_error_msg = \"Try setting an output schema\"\n\n        # Try to parse content as JSON first\n        json_data = None\n        try:\n            json_data = json.loads(content)\n        except json.JSONDecodeError:\n            json_match = re.search(json_pattern, content, re.DOTALL)\n            if json_match:\n                try:\n                    json_data = json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    return {\"content\": content, \"error\": schema_error_msg}\n            else:\n                return {\"content\": content, \"error\": schema_error_msg}\n\n        # If no output schema provided, return parsed JSON without validation\n        if not hasattr(self, \"output_schema\") or not self.output_schema or len(self.output_schema) == 0:\n            return json_data\n\n        # Use BaseModel validation with schema\n        try:\n            processed_schema = self._preprocess_schema(self.output_schema)\n            output_model = build_model_from_schema(processed_schema)\n\n            # Validate against the schema\n            if isinstance(json_data, list):\n                # Multiple objects\n                validated_objects = []\n                for item in json_data:\n                    try:\n                        validated_obj = output_model.model_validate(item)\n                        validated_objects.append(validated_obj.model_dump())\n                    except ValidationError as e:\n                        await logger.aerror(f\"Validation error for item: {e}\")\n                        # Include invalid items with error info\n                        validated_objects.append({\"data\": item, \"validation_error\": str(e)})\n                return validated_objects\n\n            # Single object\n            try:\n                validated_obj = output_model.model_validate(json_data)\n                return [validated_obj.model_dump()]  # Return as list for consistency\n            except ValidationError as e:\n                await logger.aerror(f\"Validation error: {e}\")\n                return [{\"data\": json_data, \"validation_error\": str(e)}]\n\n        except (TypeError, ValueError) as e:\n            await logger.aerror(f\"Error building structured output: {e}\")\n            # Fallback to parsed JSON without validation\n            return json_data\n\n    async def json_response(self) -> Data:\n        \"\"\"Convert agent response to structured JSON Data output with schema validation.\"\"\"\n        # Always use structured chat agent for JSON response mode for better JSON formatting\n        try:\n            system_components = []\n\n            # 1. Agent Instructions (system_prompt)\n            agent_instructions = getattr(self, \"system_prompt\", \"\") or \"\"\n            if agent_instructions:\n                system_components.append(f\"{agent_instructions}\")\n\n            # 2. Format Instructions\n            format_instructions = getattr(self, \"format_instructions\", \"\") or \"\"\n            if format_instructions:\n                system_components.append(f\"Format instructions: {format_instructions}\")\n\n            # 3. Schema Information from BaseModel\n            if hasattr(self, \"output_schema\") and self.output_schema and len(self.output_schema) > 0:\n                try:\n                    processed_schema = self._preprocess_schema(self.output_schema)\n                    output_model = build_model_from_schema(processed_schema)\n                    schema_dict = output_model.model_json_schema()\n                    schema_info = (\n                        \"You are given some text that may include format instructions, \"\n                        \"explanations, or other content alongside a JSON schema.\\n\\n\"\n                        \"Your task:\\n\"\n                        \"- Extract only the JSON schema.\\n\"\n                        \"- Return it as valid JSON.\\n\"\n                        \"- Do not include format instructions, explanations, or extra text.\\n\\n\"\n                        \"Input:\\n\"\n                        f\"{json.dumps(schema_dict, indent=2)}\\n\\n\"\n                        \"Output (only JSON schema):\"\n                    )\n                    system_components.append(schema_info)\n                except (ValidationError, ValueError, TypeError, KeyError) as e:\n                    await logger.aerror(f\"Could not build schema for prompt: {e}\", exc_info=True)\n\n            # Combine all components\n            combined_instructions = \"\\n\\n\".join(system_components) if system_components else \"\"\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=combined_instructions,\n            )\n\n            # Create and run structured chat agent\n            try:\n                structured_agent = self.create_agent_runnable()\n            except (NotImplementedError, ValueError, TypeError) as e:\n                await logger.aerror(f\"Error with structured chat agent: {e}\")\n                raise\n            try:\n                result = await self.run_agent(structured_agent)\n            except (\n                ExceptionWithMessageError,\n                ValueError,\n                TypeError,\n                RuntimeError,\n            ) as e:\n                await logger.aerror(f\"Error with structured agent result: {e}\")\n                raise\n            # Extract content from structured agent result\n            if hasattr(result, \"content\"):\n                content = result.content\n            elif hasattr(result, \"text\"):\n                content = result.text\n            else:\n                content = str(result)\n\n        except (\n            ExceptionWithMessageError,\n            ValueError,\n            TypeError,\n            NotImplementedError,\n            AttributeError,\n        ) as e:\n            await logger.aerror(f\"Error with structured chat agent: {e}\")\n            # Fallback to regular agent\n            content_str = \"No content returned from agent\"\n            return Data(data={\"content\": content_str, \"error\": str(e)})\n\n        # Process with structured output validation\n        try:\n            structured_output = await self.build_structured_output_base(content)\n\n            # Handle different output formats\n            if isinstance(structured_output, list) and structured_output:\n                if len(structured_output) == 1:\n                    return Data(data=structured_output[0])\n                return Data(data={\"results\": structured_output})\n            if isinstance(structured_output, dict):\n                return Data(data=structured_output)\n            return Data(data={\"content\": content})\n\n        except (ValueError, TypeError) as e:\n            await logger.aerror(f\"Error in structured output processing: {e}\")\n            return Data(data={\"content\": content, \"error\": str(e)})\n\n    async def get_memory_data(self):\n        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.\n        messages = (\n            await MemoryComponent(**self.get_base_args())\n            .set(\n                session_id=self.graph.session_id,\n                context_id=self.context_id,\n                order=\"Ascending\",\n                n_messages=self.n_messages,\n            )\n            .retrieve_messages()\n        )\n        return [\n            message for message in messages if getattr(message, \"id\", None) != getattr(self.input_value, \"id\", None)\n        ]\n\n    async def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except (AttributeError, ValueError, TypeError, RuntimeError) as e:\n            await logger.aerror(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {}\n        for input_ in inputs:\n            if hasattr(self, f\"{prefix}{input_.name}\"):\n                model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            # Filter out json_mode and only use attributes that exist on this component\n            model_kwargs = {}\n            for input_ in inputs:\n                if hasattr(self, f\"{prefix}{input_.name}\"):\n                    model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            if build_config is not None and field in build_config:\n                build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n                build_config[\"agent_llm\"][\"display_name\"] = \"Model Provider\"\n            elif field_value == \"connect_other_models\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    info=\"The provider of the language model that the agent will use to generate responses.\",\n                    options=[*MODEL_PROVIDERS_LIST],\n                    real_time_refresh=True,\n                    refresh_button=False,\n                    input_types=[\"LanguageModel\"],\n                    placeholder=\"Awaiting model input.\",\n                    options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST if key in MODELS_METADATA],\n                    external_options={\n                        \"fields\": {\n                            \"data\": {\n                                \"node\": {\n                                    \"name\": \"connect_other_models\",\n                                    \"display_name\": \"Connect other models\",\n                                    \"icon\": \"CornerDownLeft\",\n                                },\n                            }\n                        },\n                    },\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name_without_prefix = field_name.replace(prefix, \"\")\n                    else:\n                        field_name_without_prefix = field_name\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, field_name_without_prefix\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\",\n            tool_description=description,\n            # here we do not use the shared callbacks as we are exposing the agent as a tool\n            callbacks=self.get_langchain_callbacks(),\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n\n        return tools\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "format_instructions": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Output Format Instructions",
                "dynamic": false,
                "info": "Generic Template for structured output formatting. Valid only with Structured response.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "format_instructions",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "Your job is to search Reddit for the top discussions, news, and controversies related to the Audience in the past week."
              },
              "is_refresh": false,
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 15
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Chat History Messages",
                "dynamic": false,
                "info": "Number of chat history messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 100
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Schema Validation: Define the structure and data types for structured output. No validation if no output schema.",
                "input_types": [],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "default": "field",
                    "description": "Specify the name of the output field.",
                    "display_name": "Name",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "default": "description of field",
                    "description": "Describe the purpose of the output field.",
                    "display_name": "Description",
                    "edit_mode": "popover",
                    "formatter": "text",
                    "name": "description",
                    "type": "str"
                  },
                  {
                    "default": "str",
                    "description": "Indicate the data type of the output field (e.g., str, int, float, bool, dict).",
                    "display_name": "Type",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "type",
                    "options": [
                      "str",
                      "int",
                      "float",
                      "bool",
                      "dict"
                    ],
                    "type": "str"
                  },
                  {
                    "default": "False",
                    "description": "Set to True if this output field should be a list of the specified type.",
                    "display_name": "As List",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "multiple",
                    "type": "boolean"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks."
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-zHygU",
        "measured": {
          "height": 264,
          "width": 320
        },
        "position": {
          "x": 935,
          "y": -140.625
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenRouterComponent-a2foO",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "OpenRouter provides unified access to multiple AI models from different providers through a single API.",
            "display_name": "OpenRouter",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "api_key",
              "model_name",
              "temperature",
              "max_tokens",
              "site_url",
              "app_name"
            ],
            "frozen": false,
            "icon": "OpenRouter",
            "last_updated": "2026-01-18T21:33:44.363Z",
            "legacy": false,
            "lf_version": "1.7.2",
            "metadata": {
              "code_hash": "83c3c312a7a2",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "httpx",
                    "version": "0.28.1"
                  },
                  {
                    "name": "langchain_openai",
                    "version": "0.3.35"
                  },
                  {
                    "name": "pydantic",
                    "version": "2.11.10"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 4
              },
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ],
              "module": "lfx.components.openrouter.openrouter.OpenRouterComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "loop_types": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "loop_types": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "d0c7d5aa-5b19-4e63-80ef-34cfb0a4868b"
              },
              "_frontend_node_folder_id": {
                "value": "4260c4c1-9adb-4ff8-93b4-06fd65ff0051"
              },
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "app_name": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "App Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "app_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import httpx\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass OpenRouterComponent(LCModelComponent):\n    \"\"\"OpenRouter API component for language models.\"\"\"\n\n    display_name = \"OpenRouter\"\n    description = (\n        \"OpenRouter provides unified access to multiple AI models from different providers through a single API.\"\n    )\n    icon = \"OpenRouter\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", required=True),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            options=[],\n            value=\"\",\n            refresh_button=True,\n            real_time_refresh=True,\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            advanced=True,\n        ),\n        IntInput(name=\"max_tokens\", display_name=\"Max Tokens\", advanced=True),\n        StrInput(name=\"site_url\", display_name=\"Site URL\", advanced=True),\n        StrInput(name=\"app_name\", display_name=\"App Name\", advanced=True),\n    ]\n\n    def fetch_models(self) -> list[dict]:\n        \"\"\"Fetch available models from OpenRouter.\"\"\"\n        try:\n            response = httpx.get(\"https://openrouter.ai/api/v1/models\", timeout=10.0)\n            response.raise_for_status()\n            models = response.json().get(\"data\", [])\n            return sorted(\n                [\n                    {\n                        \"id\": m[\"id\"],\n                        \"name\": m.get(\"name\", m[\"id\"]),\n                        \"context\": m.get(\"context_length\", 0),\n                    }\n                    for m in models\n                    if m.get(\"id\")\n                ],\n                key=lambda x: x[\"name\"],\n            )\n        except (httpx.RequestError, httpx.HTTPStatusError) as e:\n            self.log(f\"Error fetching models: {e}\")\n            return []\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:  # noqa: ARG002\n        \"\"\"Update model options.\"\"\"\n        models = self.fetch_models()\n        if models:\n            build_config[\"model_name\"][\"options\"] = [m[\"id\"] for m in models]\n            build_config[\"model_name\"][\"tooltips\"] = {m[\"id\"]: f\"{m['name']} ({m['context']:,} tokens)\" for m in models}\n        else:\n            build_config[\"model_name\"][\"options\"] = [\"Failed to load models\"]\n            build_config[\"model_name\"][\"value\"] = \"Failed to load models\"\n        return build_config\n\n    def build_model(self) -> LanguageModel:\n        \"\"\"Build the OpenRouter model.\"\"\"\n        if not self.api_key:\n            msg = \"API key is required\"\n            raise ValueError(msg)\n        if not self.model_name or self.model_name == \"Loading...\":\n            msg = \"Please select a model\"\n            raise ValueError(msg)\n\n        kwargs = {\n            \"model\": self.model_name,\n            \"openai_api_key\": SecretStr(self.api_key).get_secret_value(),\n            \"openai_api_base\": \"https://openrouter.ai/api/v1\",\n            \"temperature\": self.temperature if self.temperature is not None else 0.7,\n        }\n\n        if self.max_tokens:\n            kwargs[\"max_tokens\"] = int(self.max_tokens)\n\n        headers = {}\n        if self.site_url:\n            headers[\"HTTP-Referer\"] = self.site_url\n        if self.app_name:\n            headers[\"X-Title\"] = self.app_name\n        if headers:\n            kwargs[\"default_headers\"] = headers\n\n        return ChatOpenAI(**kwargs)\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "ai21/jamba-large-1.7",
                  "ai21/jamba-mini-1.7",
                  "aion-labs/aion-1.0",
                  "aion-labs/aion-1.0-mini",
                  "aion-labs/aion-rp-llama-3.1-8b",
                  "alfredpros/codellama-7b-instruct-solidity",
                  "allenai/molmo-2-8b:free",
                  "allenai/olmo-2-0325-32b-instruct",
                  "allenai/olmo-3-32b-think",
                  "allenai/olmo-3-7b-instruct",
                  "allenai/olmo-3-7b-think",
                  "allenai/olmo-3.1-32b-instruct",
                  "allenai/olmo-3.1-32b-think",
                  "amazon/nova-2-lite-v1",
                  "amazon/nova-lite-v1",
                  "amazon/nova-micro-v1",
                  "amazon/nova-premier-v1",
                  "amazon/nova-pro-v1",
                  "anthropic/claude-3-haiku",
                  "anthropic/claude-3.5-haiku",
                  "anthropic/claude-3.5-sonnet",
                  "anthropic/claude-3.7-sonnet",
                  "anthropic/claude-3.7-sonnet:thinking",
                  "anthropic/claude-haiku-4.5",
                  "anthropic/claude-opus-4",
                  "anthropic/claude-opus-4.1",
                  "anthropic/claude-opus-4.5",
                  "anthropic/claude-sonnet-4",
                  "anthropic/claude-sonnet-4.5",
                  "arcee-ai/coder-large",
                  "arcee-ai/maestro-reasoning",
                  "arcee-ai/spotlight",
                  "arcee-ai/trinity-mini",
                  "arcee-ai/trinity-mini:free",
                  "arcee-ai/virtuoso-large",
                  "openrouter/auto",
                  "baidu/ernie-4.5-21b-a3b",
                  "baidu/ernie-4.5-21b-a3b-thinking",
                  "baidu/ernie-4.5-300b-a47b",
                  "baidu/ernie-4.5-vl-28b-a3b",
                  "baidu/ernie-4.5-vl-424b-a47b",
                  "openrouter/bodybuilder",
                  "bytedance-seed/seed-1.6",
                  "bytedance-seed/seed-1.6-flash",
                  "bytedance/ui-tars-1.5-7b",
                  "deepcogito/cogito-v2-preview-llama-109b-moe",
                  "cohere/command-a",
                  "cohere/command-r-08-2024",
                  "cohere/command-r-plus-08-2024",
                  "cohere/command-r7b-12-2024",
                  "deepcogito/cogito-v2-preview-llama-405b",
                  "deepcogito/cogito-v2-preview-llama-70b",
                  "deepcogito/cogito-v2.1-671b",
                  "deepseek/deepseek-chat",
                  "deepseek/deepseek-chat-v3-0324",
                  "deepseek/deepseek-chat-v3.1",
                  "deepseek/deepseek-v3.1-terminus",
                  "deepseek/deepseek-v3.1-terminus:exacto",
                  "deepseek/deepseek-v3.2",
                  "deepseek/deepseek-v3.2-exp",
                  "deepseek/deepseek-v3.2-speciale",
                  "deepseek/deepseek-r1",
                  "deepseek/deepseek-r1-0528",
                  "deepseek/deepseek-r1-0528:free",
                  "deepseek/deepseek-r1-distill-llama-70b",
                  "deepseek/deepseek-r1-distill-qwen-32b",
                  "eleutherai/llemma_7b",
                  "essentialai/rnj-1-instruct",
                  "alpindale/goliath-120b",
                  "google/gemini-2.0-flash-001",
                  "google/gemini-2.0-flash-exp:free",
                  "google/gemini-2.0-flash-lite-001",
                  "google/gemini-2.5-flash",
                  "google/gemini-2.5-flash-image",
                  "google/gemini-2.5-flash-lite",
                  "google/gemini-2.5-flash-lite-preview-09-2025",
                  "google/gemini-2.5-flash-preview-09-2025",
                  "google/gemini-2.5-pro",
                  "google/gemini-2.5-pro-preview-05-06",
                  "google/gemini-2.5-pro-preview",
                  "google/gemini-3-flash-preview",
                  "google/gemini-3-pro-preview",
                  "google/gemma-2-27b-it",
                  "google/gemma-2-9b-it",
                  "google/gemma-3-12b-it",
                  "google/gemma-3-12b-it:free",
                  "google/gemma-3-27b-it",
                  "google/gemma-3-27b-it:free",
                  "google/gemma-3-4b-it",
                  "google/gemma-3-4b-it:free",
                  "google/gemma-3n-e2b-it:free",
                  "google/gemma-3n-e4b-it",
                  "google/gemma-3n-e4b-it:free",
                  "google/gemini-3-pro-image-preview",
                  "ibm-granite/granite-4.0-h-micro",
                  "inception/mercury",
                  "inception/mercury-coder",
                  "inflection/inflection-3-pi",
                  "inflection/inflection-3-productivity",
                  "kwaipilot/kat-coder-pro",
                  "liquid/lfm-2.2-6b",
                  "liquid/lfm2-8b-a1b",
                  "meta-llama/llama-guard-3-8b",
                  "anthracite-org/magnum-v4-72b",
                  "mancer/weaver",
                  "meituan/longcat-flash-chat",
                  "meta-llama/llama-3-70b-instruct",
                  "meta-llama/llama-3-8b-instruct",
                  "meta-llama/llama-3.1-405b",
                  "meta-llama/llama-3.1-405b-instruct",
                  "meta-llama/llama-3.1-405b-instruct:free",
                  "meta-llama/llama-3.1-70b-instruct",
                  "meta-llama/llama-3.1-8b-instruct",
                  "meta-llama/llama-3.2-11b-vision-instruct",
                  "meta-llama/llama-3.2-1b-instruct",
                  "meta-llama/llama-3.2-3b-instruct",
                  "meta-llama/llama-3.2-3b-instruct:free",
                  "meta-llama/llama-3.3-70b-instruct",
                  "meta-llama/llama-3.3-70b-instruct:free",
                  "meta-llama/llama-4-maverick",
                  "meta-llama/llama-4-scout",
                  "meta-llama/llama-guard-4-12b",
                  "meta-llama/llama-guard-2-8b",
                  "microsoft/phi-4",
                  "minimax/minimax-m1",
                  "minimax/minimax-m2",
                  "minimax/minimax-m2.1",
                  "minimax/minimax-01",
                  "mistralai/mistral-large",
                  "mistralai/mistral-large-2407",
                  "mistralai/mistral-large-2411",
                  "mistralai/mistral-tiny",
                  "mistralai/codestral-2508",
                  "mistralai/devstral-2512",
                  "mistralai/devstral-2512:free",
                  "mistralai/devstral-medium",
                  "mistralai/devstral-small",
                  "mistralai/ministral-14b-2512",
                  "mistralai/ministral-3b-2512",
                  "mistralai/ministral-8b-2512",
                  "mistralai/ministral-3b",
                  "mistralai/ministral-8b",
                  "mistralai/mistral-7b-instruct",
                  "mistralai/mistral-7b-instruct-v0.1",
                  "mistralai/mistral-7b-instruct-v0.2",
                  "mistralai/mistral-7b-instruct-v0.3",
                  "mistralai/mistral-large-2512",
                  "mistralai/mistral-medium-3",
                  "mistralai/mistral-medium-3.1",
                  "mistralai/mistral-nemo",
                  "mistralai/mistral-small-24b-instruct-2501",
                  "mistralai/mistral-small-3.1-24b-instruct",
                  "mistralai/mistral-small-3.1-24b-instruct:free",
                  "mistralai/mistral-small-3.2-24b-instruct",
                  "mistralai/mistral-small-creative",
                  "mistralai/mixtral-8x22b-instruct",
                  "mistralai/mixtral-8x7b-instruct",
                  "mistralai/pixtral-12b",
                  "mistralai/pixtral-large-2411",
                  "mistralai/mistral-saba",
                  "mistralai/voxtral-small-24b-2507",
                  "moonshotai/kimi-dev-72b",
                  "moonshotai/kimi-k2",
                  "moonshotai/kimi-k2:free",
                  "moonshotai/kimi-k2-0905",
                  "moonshotai/kimi-k2-0905:exacto",
                  "moonshotai/kimi-k2-thinking",
                  "morph/morph-v3-fast",
                  "morph/morph-v3-large",
                  "gryphe/mythomax-l2-13b",
                  "nvidia/llama-3.1-nemotron-70b-instruct",
                  "nvidia/llama-3.1-nemotron-ultra-253b-v1",
                  "nvidia/llama-3.3-nemotron-super-49b-v1.5",
                  "nvidia/nemotron-3-nano-30b-a3b",
                  "nvidia/nemotron-3-nano-30b-a3b:free",
                  "nvidia/nemotron-nano-12b-v2-vl",
                  "nvidia/nemotron-nano-12b-v2-vl:free",
                  "nvidia/nemotron-nano-9b-v2",
                  "nvidia/nemotron-nano-9b-v2:free",
                  "neversleep/llama-3.1-lumimaid-8b",
                  "nex-agi/deepseek-v3.1-nex-n1",
                  "neversleep/noromaid-20b",
                  "nousresearch/deephermes-3-mistral-24b-preview",
                  "nousresearch/hermes-3-llama-3.1-405b",
                  "nousresearch/hermes-3-llama-3.1-405b:free",
                  "nousresearch/hermes-3-llama-3.1-70b",
                  "nousresearch/hermes-4-405b",
                  "nousresearch/hermes-4-70b",
                  "nousresearch/hermes-2-pro-llama-3-8b",
                  "openai/chatgpt-4o-latest",
                  "openai/gpt-3.5-turbo",
                  "openai/gpt-3.5-turbo-0613",
                  "openai/gpt-3.5-turbo-16k",
                  "openai/gpt-3.5-turbo-instruct",
                  "openai/gpt-4",
                  "openai/gpt-4-0314",
                  "openai/gpt-4-turbo",
                  "openai/gpt-4-1106-preview",
                  "openai/gpt-4-turbo-preview",
                  "openai/gpt-4.1",
                  "openai/gpt-4.1-mini",
                  "openai/gpt-4.1-nano",
                  "openai/gpt-4o",
                  "openai/gpt-4o-2024-05-13",
                  "openai/gpt-4o-2024-08-06",
                  "openai/gpt-4o-2024-11-20",
                  "openai/gpt-4o:extended",
                  "openai/gpt-4o-audio-preview",
                  "openai/gpt-4o-search-preview",
                  "openai/gpt-4o-mini",
                  "openai/gpt-4o-mini-2024-07-18",
                  "openai/gpt-4o-mini-search-preview",
                  "openai/gpt-5",
                  "openai/gpt-5-chat",
                  "openai/gpt-5-codex",
                  "openai/gpt-5-image",
                  "openai/gpt-5-image-mini",
                  "openai/gpt-5-mini",
                  "openai/gpt-5-nano",
                  "openai/gpt-5-pro",
                  "openai/gpt-5.1",
                  "openai/gpt-5.1-chat",
                  "openai/gpt-5.1-codex",
                  "openai/gpt-5.1-codex-max",
                  "openai/gpt-5.1-codex-mini",
                  "openai/gpt-5.2",
                  "openai/gpt-5.2-chat",
                  "openai/gpt-5.2-pro",
                  "openai/gpt-5.2-codex",
                  "openai/gpt-oss-120b",
                  "openai/gpt-oss-120b:exacto",
                  "openai/gpt-oss-120b:free",
                  "openai/gpt-oss-20b",
                  "openai/gpt-oss-20b:free",
                  "openai/gpt-oss-safeguard-20b",
                  "openai/o1",
                  "openai/o1-pro",
                  "openai/o3",
                  "openai/o3-deep-research",
                  "openai/o3-mini",
                  "openai/o3-mini-high",
                  "openai/o3-pro",
                  "openai/o4-mini",
                  "openai/o4-mini-deep-research",
                  "openai/o4-mini-high",
                  "opengvlab/internvl3-78b",
                  "perplexity/sonar",
                  "perplexity/sonar-deep-research",
                  "perplexity/sonar-pro",
                  "perplexity/sonar-pro-search",
                  "perplexity/sonar-reasoning-pro",
                  "prime-intellect/intellect-3",
                  "qwen/qwen-2.5-72b-instruct",
                  "qwen/qwen-2.5-coder-32b-instruct",
                  "qwen/qwq-32b",
                  "qwen/qwen-plus-2025-07-28",
                  "qwen/qwen-plus-2025-07-28:thinking",
                  "qwen/qwen-vl-max",
                  "qwen/qwen-vl-plus",
                  "qwen/qwen-max",
                  "qwen/qwen-plus",
                  "qwen/qwen-turbo",
                  "qwen/qwen-2.5-7b-instruct",
                  "qwen/qwen2.5-coder-7b-instruct",
                  "qwen/qwen2.5-vl-32b-instruct",
                  "qwen/qwen2.5-vl-72b-instruct",
                  "qwen/qwen-2.5-vl-7b-instruct",
                  "qwen/qwen-2.5-vl-7b-instruct:free",
                  "qwen/qwen3-14b",
                  "qwen/qwen3-235b-a22b",
                  "qwen/qwen3-235b-a22b-2507",
                  "qwen/qwen3-235b-a22b-thinking-2507",
                  "qwen/qwen3-30b-a3b",
                  "qwen/qwen3-30b-a3b-instruct-2507",
                  "qwen/qwen3-30b-a3b-thinking-2507",
                  "qwen/qwen3-32b",
                  "qwen/qwen3-4b:free",
                  "qwen/qwen3-8b",
                  "qwen/qwen3-coder-30b-a3b-instruct",
                  "qwen/qwen3-coder",
                  "qwen/qwen3-coder:exacto",
                  "qwen/qwen3-coder:free",
                  "qwen/qwen3-coder-flash",
                  "qwen/qwen3-coder-plus",
                  "qwen/qwen3-max",
                  "qwen/qwen3-next-80b-a3b-instruct",
                  "qwen/qwen3-next-80b-a3b-instruct:free",
                  "qwen/qwen3-next-80b-a3b-thinking",
                  "qwen/qwen3-vl-235b-a22b-instruct",
                  "qwen/qwen3-vl-235b-a22b-thinking",
                  "qwen/qwen3-vl-30b-a3b-instruct",
                  "qwen/qwen3-vl-30b-a3b-thinking",
                  "qwen/qwen3-vl-32b-instruct",
                  "qwen/qwen3-vl-8b-instruct",
                  "qwen/qwen3-vl-8b-thinking",
                  "undi95/remm-slerp-l2-13b",
                  "relace/relace-apply-3",
                  "relace/relace-search",
                  "sao10k/l3-lunaris-8b",
                  "sao10k/l3.1-70b-hanami-x1",
                  "sao10k/l3.1-euryale-70b",
                  "sao10k/l3.3-euryale-70b",
                  "sao10k/l3-euryale-70b",
                  "raifle/sorcererlm-8x22b",
                  "stepfun-ai/step3",
                  "switchpoint/router",
                  "tngtech/deepseek-r1t-chimera",
                  "tngtech/deepseek-r1t-chimera:free",
                  "tngtech/deepseek-r1t2-chimera",
                  "tngtech/deepseek-r1t2-chimera:free",
                  "tngtech/tng-r1t-chimera",
                  "tngtech/tng-r1t-chimera:free",
                  "tencent/hunyuan-a13b-instruct",
                  "thedrummer/cydonia-24b-v4.1",
                  "thedrummer/rocinante-12b",
                  "thedrummer/skyfall-36b-v2",
                  "thedrummer/unslopnemo-12b",
                  "alibaba/tongyi-deepresearch-30b-a3b",
                  "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
                  "microsoft/wizardlm-2-8x22b",
                  "xiaomi/mimo-v2-flash",
                  "xiaomi/mimo-v2-flash:free",
                  "z-ai/glm-4-32b",
                  "z-ai/glm-4.5",
                  "z-ai/glm-4.5-air",
                  "z-ai/glm-4.5-air:free",
                  "z-ai/glm-4.5v",
                  "z-ai/glm-4.6",
                  "z-ai/glm-4.6:exacto",
                  "z-ai/glm-4.6v",
                  "z-ai/glm-4.7",
                  "x-ai/grok-3",
                  "x-ai/grok-3-beta",
                  "x-ai/grok-3-mini",
                  "x-ai/grok-3-mini-beta",
                  "x-ai/grok-4",
                  "x-ai/grok-4-fast",
                  "x-ai/grok-4.1-fast",
                  "x-ai/grok-code-fast-1"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "tooltips": {
                  "ai21/jamba-large-1.7": "AI21: Jamba Large 1.7 (256,000 tokens)",
                  "ai21/jamba-mini-1.7": "AI21: Jamba Mini 1.7 (256,000 tokens)",
                  "aion-labs/aion-1.0": "AionLabs: Aion-1.0 (131,072 tokens)",
                  "aion-labs/aion-1.0-mini": "AionLabs: Aion-1.0-Mini (131,072 tokens)",
                  "aion-labs/aion-rp-llama-3.1-8b": "AionLabs: Aion-RP 1.0 (8B) (32,768 tokens)",
                  "alfredpros/codellama-7b-instruct-solidity": "AlfredPros: CodeLLaMa 7B Instruct Solidity (4,096 tokens)",
                  "alibaba/tongyi-deepresearch-30b-a3b": "Tongyi DeepResearch 30B A3B (131,072 tokens)",
                  "allenai/molmo-2-8b:free": "AllenAI: Molmo2 8B (free) (36,864 tokens)",
                  "allenai/olmo-2-0325-32b-instruct": "AllenAI: Olmo 2 32B Instruct (128,000 tokens)",
                  "allenai/olmo-3-32b-think": "AllenAI: Olmo 3 32B Think (65,536 tokens)",
                  "allenai/olmo-3-7b-instruct": "AllenAI: Olmo 3 7B Instruct (65,536 tokens)",
                  "allenai/olmo-3-7b-think": "AllenAI: Olmo 3 7B Think (65,536 tokens)",
                  "allenai/olmo-3.1-32b-instruct": "AllenAI: Olmo 3.1 32B Instruct (65,536 tokens)",
                  "allenai/olmo-3.1-32b-think": "AllenAI: Olmo 3.1 32B Think (65,536 tokens)",
                  "alpindale/goliath-120b": "Goliath 120B (6,144 tokens)",
                  "amazon/nova-2-lite-v1": "Amazon: Nova 2 Lite (1,000,000 tokens)",
                  "amazon/nova-lite-v1": "Amazon: Nova Lite 1.0 (300,000 tokens)",
                  "amazon/nova-micro-v1": "Amazon: Nova Micro 1.0 (128,000 tokens)",
                  "amazon/nova-premier-v1": "Amazon: Nova Premier 1.0 (1,000,000 tokens)",
                  "amazon/nova-pro-v1": "Amazon: Nova Pro 1.0 (300,000 tokens)",
                  "anthracite-org/magnum-v4-72b": "Magnum v4 72B (16,384 tokens)",
                  "anthropic/claude-3-haiku": "Anthropic: Claude 3 Haiku (200,000 tokens)",
                  "anthropic/claude-3.5-haiku": "Anthropic: Claude 3.5 Haiku (200,000 tokens)",
                  "anthropic/claude-3.5-sonnet": "Anthropic: Claude 3.5 Sonnet (200,000 tokens)",
                  "anthropic/claude-3.7-sonnet": "Anthropic: Claude 3.7 Sonnet (200,000 tokens)",
                  "anthropic/claude-3.7-sonnet:thinking": "Anthropic: Claude 3.7 Sonnet (thinking) (200,000 tokens)",
                  "anthropic/claude-haiku-4.5": "Anthropic: Claude Haiku 4.5 (200,000 tokens)",
                  "anthropic/claude-opus-4": "Anthropic: Claude Opus 4 (200,000 tokens)",
                  "anthropic/claude-opus-4.1": "Anthropic: Claude Opus 4.1 (200,000 tokens)",
                  "anthropic/claude-opus-4.5": "Anthropic: Claude Opus 4.5 (200,000 tokens)",
                  "anthropic/claude-sonnet-4": "Anthropic: Claude Sonnet 4 (1,000,000 tokens)",
                  "anthropic/claude-sonnet-4.5": "Anthropic: Claude Sonnet 4.5 (1,000,000 tokens)",
                  "arcee-ai/coder-large": "Arcee AI: Coder Large (32,768 tokens)",
                  "arcee-ai/maestro-reasoning": "Arcee AI: Maestro Reasoning (131,072 tokens)",
                  "arcee-ai/spotlight": "Arcee AI: Spotlight (131,072 tokens)",
                  "arcee-ai/trinity-mini": "Arcee AI: Trinity Mini (131,072 tokens)",
                  "arcee-ai/trinity-mini:free": "Arcee AI: Trinity Mini (free) (131,072 tokens)",
                  "arcee-ai/virtuoso-large": "Arcee AI: Virtuoso Large (131,072 tokens)",
                  "baidu/ernie-4.5-21b-a3b": "Baidu: ERNIE 4.5 21B A3B (120,000 tokens)",
                  "baidu/ernie-4.5-21b-a3b-thinking": "Baidu: ERNIE 4.5 21B A3B Thinking (131,072 tokens)",
                  "baidu/ernie-4.5-300b-a47b": "Baidu: ERNIE 4.5 300B A47B  (123,000 tokens)",
                  "baidu/ernie-4.5-vl-28b-a3b": "Baidu: ERNIE 4.5 VL 28B A3B (30,000 tokens)",
                  "baidu/ernie-4.5-vl-424b-a47b": "Baidu: ERNIE 4.5 VL 424B A47B  (123,000 tokens)",
                  "bytedance-seed/seed-1.6": "ByteDance Seed: Seed 1.6 (262,144 tokens)",
                  "bytedance-seed/seed-1.6-flash": "ByteDance Seed: Seed 1.6 Flash (262,144 tokens)",
                  "bytedance/ui-tars-1.5-7b": "ByteDance: UI-TARS 7B  (128,000 tokens)",
                  "cognitivecomputations/dolphin-mistral-24b-venice-edition:free": "Venice: Uncensored (free) (32,768 tokens)",
                  "cohere/command-a": "Cohere: Command A (256,000 tokens)",
                  "cohere/command-r-08-2024": "Cohere: Command R (08-2024) (128,000 tokens)",
                  "cohere/command-r-plus-08-2024": "Cohere: Command R+ (08-2024) (128,000 tokens)",
                  "cohere/command-r7b-12-2024": "Cohere: Command R7B (12-2024) (128,000 tokens)",
                  "deepcogito/cogito-v2-preview-llama-109b-moe": "Cogito V2 Preview Llama 109B (32,767 tokens)",
                  "deepcogito/cogito-v2-preview-llama-405b": "Deep Cogito: Cogito V2 Preview Llama 405B (32,768 tokens)",
                  "deepcogito/cogito-v2-preview-llama-70b": "Deep Cogito: Cogito V2 Preview Llama 70B (32,768 tokens)",
                  "deepcogito/cogito-v2.1-671b": "Deep Cogito: Cogito v2.1 671B (128,000 tokens)",
                  "deepseek/deepseek-chat": "DeepSeek: DeepSeek V3 (163,840 tokens)",
                  "deepseek/deepseek-chat-v3-0324": "DeepSeek: DeepSeek V3 0324 (163,840 tokens)",
                  "deepseek/deepseek-chat-v3.1": "DeepSeek: DeepSeek V3.1 (32,768 tokens)",
                  "deepseek/deepseek-r1": "DeepSeek: R1 (64,000 tokens)",
                  "deepseek/deepseek-r1-0528": "DeepSeek: R1 0528 (163,840 tokens)",
                  "deepseek/deepseek-r1-0528:free": "DeepSeek: R1 0528 (free) (163,840 tokens)",
                  "deepseek/deepseek-r1-distill-llama-70b": "DeepSeek: R1 Distill Llama 70B (131,072 tokens)",
                  "deepseek/deepseek-r1-distill-qwen-32b": "DeepSeek: R1 Distill Qwen 32B (32,768 tokens)",
                  "deepseek/deepseek-v3.1-terminus": "DeepSeek: DeepSeek V3.1 Terminus (163,840 tokens)",
                  "deepseek/deepseek-v3.1-terminus:exacto": "DeepSeek: DeepSeek V3.1 Terminus (exacto) (163,840 tokens)",
                  "deepseek/deepseek-v3.2": "DeepSeek: DeepSeek V3.2 (163,840 tokens)",
                  "deepseek/deepseek-v3.2-exp": "DeepSeek: DeepSeek V3.2 Exp (163,840 tokens)",
                  "deepseek/deepseek-v3.2-speciale": "DeepSeek: DeepSeek V3.2 Speciale (163,840 tokens)",
                  "eleutherai/llemma_7b": "EleutherAI: Llemma 7b (4,096 tokens)",
                  "essentialai/rnj-1-instruct": "EssentialAI: Rnj 1 Instruct (32,768 tokens)",
                  "google/gemini-2.0-flash-001": "Google: Gemini 2.0 Flash (1,048,576 tokens)",
                  "google/gemini-2.0-flash-exp:free": "Google: Gemini 2.0 Flash Experimental (free) (1,048,576 tokens)",
                  "google/gemini-2.0-flash-lite-001": "Google: Gemini 2.0 Flash Lite (1,048,576 tokens)",
                  "google/gemini-2.5-flash": "Google: Gemini 2.5 Flash (1,048,576 tokens)",
                  "google/gemini-2.5-flash-image": "Google: Gemini 2.5 Flash Image (Nano Banana) (32,768 tokens)",
                  "google/gemini-2.5-flash-lite": "Google: Gemini 2.5 Flash Lite (1,048,576 tokens)",
                  "google/gemini-2.5-flash-lite-preview-09-2025": "Google: Gemini 2.5 Flash Lite Preview 09-2025 (1,048,576 tokens)",
                  "google/gemini-2.5-flash-preview-09-2025": "Google: Gemini 2.5 Flash Preview 09-2025 (1,048,576 tokens)",
                  "google/gemini-2.5-pro": "Google: Gemini 2.5 Pro (1,048,576 tokens)",
                  "google/gemini-2.5-pro-preview": "Google: Gemini 2.5 Pro Preview 06-05 (1,048,576 tokens)",
                  "google/gemini-2.5-pro-preview-05-06": "Google: Gemini 2.5 Pro Preview 05-06 (1,048,576 tokens)",
                  "google/gemini-3-flash-preview": "Google: Gemini 3 Flash Preview (1,048,576 tokens)",
                  "google/gemini-3-pro-image-preview": "Google: Nano Banana Pro (Gemini 3 Pro Image Preview) (65,536 tokens)",
                  "google/gemini-3-pro-preview": "Google: Gemini 3 Pro Preview (1,048,576 tokens)",
                  "google/gemma-2-27b-it": "Google: Gemma 2 27B (8,192 tokens)",
                  "google/gemma-2-9b-it": "Google: Gemma 2 9B (8,192 tokens)",
                  "google/gemma-3-12b-it": "Google: Gemma 3 12B (131,072 tokens)",
                  "google/gemma-3-12b-it:free": "Google: Gemma 3 12B (free) (32,768 tokens)",
                  "google/gemma-3-27b-it": "Google: Gemma 3 27B (96,000 tokens)",
                  "google/gemma-3-27b-it:free": "Google: Gemma 3 27B (free) (131,072 tokens)",
                  "google/gemma-3-4b-it": "Google: Gemma 3 4B (96,000 tokens)",
                  "google/gemma-3-4b-it:free": "Google: Gemma 3 4B (free) (32,768 tokens)",
                  "google/gemma-3n-e2b-it:free": "Google: Gemma 3n 2B (free) (8,192 tokens)",
                  "google/gemma-3n-e4b-it": "Google: Gemma 3n 4B (32,768 tokens)",
                  "google/gemma-3n-e4b-it:free": "Google: Gemma 3n 4B (free) (8,192 tokens)",
                  "gryphe/mythomax-l2-13b": "MythoMax 13B (4,096 tokens)",
                  "ibm-granite/granite-4.0-h-micro": "IBM: Granite 4.0 Micro (131,000 tokens)",
                  "inception/mercury": "Inception: Mercury (128,000 tokens)",
                  "inception/mercury-coder": "Inception: Mercury Coder (128,000 tokens)",
                  "inflection/inflection-3-pi": "Inflection: Inflection 3 Pi (8,000 tokens)",
                  "inflection/inflection-3-productivity": "Inflection: Inflection 3 Productivity (8,000 tokens)",
                  "kwaipilot/kat-coder-pro": "Kwaipilot: KAT-Coder-Pro V1 (256,000 tokens)",
                  "liquid/lfm-2.2-6b": "LiquidAI/LFM2-2.6B (32,768 tokens)",
                  "liquid/lfm2-8b-a1b": "LiquidAI/LFM2-8B-A1B (32,768 tokens)",
                  "mancer/weaver": "Mancer: Weaver (alpha) (8,000 tokens)",
                  "meituan/longcat-flash-chat": "Meituan: LongCat Flash Chat (131,072 tokens)",
                  "meta-llama/llama-3-70b-instruct": "Meta: Llama 3 70B Instruct (8,192 tokens)",
                  "meta-llama/llama-3-8b-instruct": "Meta: Llama 3 8B Instruct (8,192 tokens)",
                  "meta-llama/llama-3.1-405b": "Meta: Llama 3.1 405B (base) (32,768 tokens)",
                  "meta-llama/llama-3.1-405b-instruct": "Meta: Llama 3.1 405B Instruct (10,000 tokens)",
                  "meta-llama/llama-3.1-405b-instruct:free": "Meta: Llama 3.1 405B Instruct (free) (131,072 tokens)",
                  "meta-llama/llama-3.1-70b-instruct": "Meta: Llama 3.1 70B Instruct (131,072 tokens)",
                  "meta-llama/llama-3.1-8b-instruct": "Meta: Llama 3.1 8B Instruct (16,384 tokens)",
                  "meta-llama/llama-3.2-11b-vision-instruct": "Meta: Llama 3.2 11B Vision Instruct (131,072 tokens)",
                  "meta-llama/llama-3.2-1b-instruct": "Meta: Llama 3.2 1B Instruct (60,000 tokens)",
                  "meta-llama/llama-3.2-3b-instruct": "Meta: Llama 3.2 3B Instruct (131,072 tokens)",
                  "meta-llama/llama-3.2-3b-instruct:free": "Meta: Llama 3.2 3B Instruct (free) (131,072 tokens)",
                  "meta-llama/llama-3.3-70b-instruct": "Meta: Llama 3.3 70B Instruct (131,072 tokens)",
                  "meta-llama/llama-3.3-70b-instruct:free": "Meta: Llama 3.3 70B Instruct (free) (131,072 tokens)",
                  "meta-llama/llama-4-maverick": "Meta: Llama 4 Maverick (1,048,576 tokens)",
                  "meta-llama/llama-4-scout": "Meta: Llama 4 Scout (327,680 tokens)",
                  "meta-llama/llama-guard-2-8b": "Meta: LlamaGuard 2 8B (8,192 tokens)",
                  "meta-llama/llama-guard-3-8b": "Llama Guard 3 8B (131,072 tokens)",
                  "meta-llama/llama-guard-4-12b": "Meta: Llama Guard 4 12B (163,840 tokens)",
                  "microsoft/phi-4": "Microsoft: Phi 4 (16,384 tokens)",
                  "microsoft/wizardlm-2-8x22b": "WizardLM-2 8x22B (65,536 tokens)",
                  "minimax/minimax-01": "MiniMax: MiniMax-01 (1,000,192 tokens)",
                  "minimax/minimax-m1": "MiniMax: MiniMax M1 (1,000,000 tokens)",
                  "minimax/minimax-m2": "MiniMax: MiniMax M2 (196,608 tokens)",
                  "minimax/minimax-m2.1": "MiniMax: MiniMax M2.1 (196,608 tokens)",
                  "mistralai/codestral-2508": "Mistral: Codestral 2508 (256,000 tokens)",
                  "mistralai/devstral-2512": "Mistral: Devstral 2 2512 (262,144 tokens)",
                  "mistralai/devstral-2512:free": "Mistral: Devstral 2 2512 (free) (262,144 tokens)",
                  "mistralai/devstral-medium": "Mistral: Devstral Medium (131,072 tokens)",
                  "mistralai/devstral-small": "Mistral: Devstral Small 1.1 (131,072 tokens)",
                  "mistralai/ministral-14b-2512": "Mistral: Ministral 3 14B 2512 (262,144 tokens)",
                  "mistralai/ministral-3b": "Mistral: Ministral 3B (131,072 tokens)",
                  "mistralai/ministral-3b-2512": "Mistral: Ministral 3 3B 2512 (131,072 tokens)",
                  "mistralai/ministral-8b": "Mistral: Ministral 8B (131,072 tokens)",
                  "mistralai/ministral-8b-2512": "Mistral: Ministral 3 8B 2512 (262,144 tokens)",
                  "mistralai/mistral-7b-instruct": "Mistral: Mistral 7B Instruct (32,768 tokens)",
                  "mistralai/mistral-7b-instruct-v0.1": "Mistral: Mistral 7B Instruct v0.1 (2,824 tokens)",
                  "mistralai/mistral-7b-instruct-v0.2": "Mistral: Mistral 7B Instruct v0.2 (32,768 tokens)",
                  "mistralai/mistral-7b-instruct-v0.3": "Mistral: Mistral 7B Instruct v0.3 (32,768 tokens)",
                  "mistralai/mistral-large": "Mistral Large (128,000 tokens)",
                  "mistralai/mistral-large-2407": "Mistral Large 2407 (131,072 tokens)",
                  "mistralai/mistral-large-2411": "Mistral Large 2411 (131,072 tokens)",
                  "mistralai/mistral-large-2512": "Mistral: Mistral Large 3 2512 (262,144 tokens)",
                  "mistralai/mistral-medium-3": "Mistral: Mistral Medium 3 (131,072 tokens)",
                  "mistralai/mistral-medium-3.1": "Mistral: Mistral Medium 3.1 (131,072 tokens)",
                  "mistralai/mistral-nemo": "Mistral: Mistral Nemo (131,072 tokens)",
                  "mistralai/mistral-saba": "Mistral: Saba (32,768 tokens)",
                  "mistralai/mistral-small-24b-instruct-2501": "Mistral: Mistral Small 3 (32,768 tokens)",
                  "mistralai/mistral-small-3.1-24b-instruct": "Mistral: Mistral Small 3.1 24B (131,072 tokens)",
                  "mistralai/mistral-small-3.1-24b-instruct:free": "Mistral: Mistral Small 3.1 24B (free) (128,000 tokens)",
                  "mistralai/mistral-small-3.2-24b-instruct": "Mistral: Mistral Small 3.2 24B (131,072 tokens)",
                  "mistralai/mistral-small-creative": "Mistral: Mistral Small Creative (32,768 tokens)",
                  "mistralai/mistral-tiny": "Mistral Tiny (32,768 tokens)",
                  "mistralai/mixtral-8x22b-instruct": "Mistral: Mixtral 8x22B Instruct (65,536 tokens)",
                  "mistralai/mixtral-8x7b-instruct": "Mistral: Mixtral 8x7B Instruct (32,768 tokens)",
                  "mistralai/pixtral-12b": "Mistral: Pixtral 12B (32,768 tokens)",
                  "mistralai/pixtral-large-2411": "Mistral: Pixtral Large 2411 (131,072 tokens)",
                  "mistralai/voxtral-small-24b-2507": "Mistral: Voxtral Small 24B 2507 (32,000 tokens)",
                  "moonshotai/kimi-dev-72b": "MoonshotAI: Kimi Dev 72B (131,072 tokens)",
                  "moonshotai/kimi-k2": "MoonshotAI: Kimi K2 0711 (131,072 tokens)",
                  "moonshotai/kimi-k2-0905": "MoonshotAI: Kimi K2 0905 (262,144 tokens)",
                  "moonshotai/kimi-k2-0905:exacto": "MoonshotAI: Kimi K2 0905 (exacto) (262,144 tokens)",
                  "moonshotai/kimi-k2-thinking": "MoonshotAI: Kimi K2 Thinking (262,144 tokens)",
                  "moonshotai/kimi-k2:free": "MoonshotAI: Kimi K2 0711 (free) (32,768 tokens)",
                  "morph/morph-v3-fast": "Morph: Morph V3 Fast (81,920 tokens)",
                  "morph/morph-v3-large": "Morph: Morph V3 Large (262,144 tokens)",
                  "neversleep/llama-3.1-lumimaid-8b": "NeverSleep: Lumimaid v0.2 8B (32,768 tokens)",
                  "neversleep/noromaid-20b": "Noromaid 20B (4,096 tokens)",
                  "nex-agi/deepseek-v3.1-nex-n1": "Nex AGI: DeepSeek V3.1 Nex N1 (131,072 tokens)",
                  "nousresearch/deephermes-3-mistral-24b-preview": "Nous: DeepHermes 3 Mistral 24B Preview (32,768 tokens)",
                  "nousresearch/hermes-2-pro-llama-3-8b": "NousResearch: Hermes 2 Pro - Llama-3 8B (8,192 tokens)",
                  "nousresearch/hermes-3-llama-3.1-405b": "Nous: Hermes 3 405B Instruct (131,072 tokens)",
                  "nousresearch/hermes-3-llama-3.1-405b:free": "Nous: Hermes 3 405B Instruct (free) (131,072 tokens)",
                  "nousresearch/hermes-3-llama-3.1-70b": "Nous: Hermes 3 70B Instruct (65,536 tokens)",
                  "nousresearch/hermes-4-405b": "Nous: Hermes 4 405B (131,072 tokens)",
                  "nousresearch/hermes-4-70b": "Nous: Hermes 4 70B (131,072 tokens)",
                  "nvidia/llama-3.1-nemotron-70b-instruct": "NVIDIA: Llama 3.1 Nemotron 70B Instruct (131,072 tokens)",
                  "nvidia/llama-3.1-nemotron-ultra-253b-v1": "NVIDIA: Llama 3.1 Nemotron Ultra 253B v1 (131,072 tokens)",
                  "nvidia/llama-3.3-nemotron-super-49b-v1.5": "NVIDIA: Llama 3.3 Nemotron Super 49B V1.5 (131,072 tokens)",
                  "nvidia/nemotron-3-nano-30b-a3b": "NVIDIA: Nemotron 3 Nano 30B A3B (262,144 tokens)",
                  "nvidia/nemotron-3-nano-30b-a3b:free": "NVIDIA: Nemotron 3 Nano 30B A3B (free) (256,000 tokens)",
                  "nvidia/nemotron-nano-12b-v2-vl": "NVIDIA: Nemotron Nano 12B 2 VL (131,072 tokens)",
                  "nvidia/nemotron-nano-12b-v2-vl:free": "NVIDIA: Nemotron Nano 12B 2 VL (free) (128,000 tokens)",
                  "nvidia/nemotron-nano-9b-v2": "NVIDIA: Nemotron Nano 9B V2 (131,072 tokens)",
                  "nvidia/nemotron-nano-9b-v2:free": "NVIDIA: Nemotron Nano 9B V2 (free) (128,000 tokens)",
                  "openai/chatgpt-4o-latest": "OpenAI: ChatGPT-4o (128,000 tokens)",
                  "openai/gpt-3.5-turbo": "OpenAI: GPT-3.5 Turbo (16,385 tokens)",
                  "openai/gpt-3.5-turbo-0613": "OpenAI: GPT-3.5 Turbo (older v0613) (4,095 tokens)",
                  "openai/gpt-3.5-turbo-16k": "OpenAI: GPT-3.5 Turbo 16k (16,385 tokens)",
                  "openai/gpt-3.5-turbo-instruct": "OpenAI: GPT-3.5 Turbo Instruct (4,095 tokens)",
                  "openai/gpt-4": "OpenAI: GPT-4 (8,191 tokens)",
                  "openai/gpt-4-0314": "OpenAI: GPT-4 (older v0314) (8,191 tokens)",
                  "openai/gpt-4-1106-preview": "OpenAI: GPT-4 Turbo (older v1106) (128,000 tokens)",
                  "openai/gpt-4-turbo": "OpenAI: GPT-4 Turbo (128,000 tokens)",
                  "openai/gpt-4-turbo-preview": "OpenAI: GPT-4 Turbo Preview (128,000 tokens)",
                  "openai/gpt-4.1": "OpenAI: GPT-4.1 (1,047,576 tokens)",
                  "openai/gpt-4.1-mini": "OpenAI: GPT-4.1 Mini (1,047,576 tokens)",
                  "openai/gpt-4.1-nano": "OpenAI: GPT-4.1 Nano (1,047,576 tokens)",
                  "openai/gpt-4o": "OpenAI: GPT-4o (128,000 tokens)",
                  "openai/gpt-4o-2024-05-13": "OpenAI: GPT-4o (2024-05-13) (128,000 tokens)",
                  "openai/gpt-4o-2024-08-06": "OpenAI: GPT-4o (2024-08-06) (128,000 tokens)",
                  "openai/gpt-4o-2024-11-20": "OpenAI: GPT-4o (2024-11-20) (128,000 tokens)",
                  "openai/gpt-4o-audio-preview": "OpenAI: GPT-4o Audio (128,000 tokens)",
                  "openai/gpt-4o-mini": "OpenAI: GPT-4o-mini (128,000 tokens)",
                  "openai/gpt-4o-mini-2024-07-18": "OpenAI: GPT-4o-mini (2024-07-18) (128,000 tokens)",
                  "openai/gpt-4o-mini-search-preview": "OpenAI: GPT-4o-mini Search Preview (128,000 tokens)",
                  "openai/gpt-4o-search-preview": "OpenAI: GPT-4o Search Preview (128,000 tokens)",
                  "openai/gpt-4o:extended": "OpenAI: GPT-4o (extended) (128,000 tokens)",
                  "openai/gpt-5": "OpenAI: GPT-5 (400,000 tokens)",
                  "openai/gpt-5-chat": "OpenAI: GPT-5 Chat (128,000 tokens)",
                  "openai/gpt-5-codex": "OpenAI: GPT-5 Codex (400,000 tokens)",
                  "openai/gpt-5-image": "OpenAI: GPT-5 Image (400,000 tokens)",
                  "openai/gpt-5-image-mini": "OpenAI: GPT-5 Image Mini (400,000 tokens)",
                  "openai/gpt-5-mini": "OpenAI: GPT-5 Mini (400,000 tokens)",
                  "openai/gpt-5-nano": "OpenAI: GPT-5 Nano (400,000 tokens)",
                  "openai/gpt-5-pro": "OpenAI: GPT-5 Pro (400,000 tokens)",
                  "openai/gpt-5.1": "OpenAI: GPT-5.1 (400,000 tokens)",
                  "openai/gpt-5.1-chat": "OpenAI: GPT-5.1 Chat (128,000 tokens)",
                  "openai/gpt-5.1-codex": "OpenAI: GPT-5.1-Codex (400,000 tokens)",
                  "openai/gpt-5.1-codex-max": "OpenAI: GPT-5.1-Codex-Max (400,000 tokens)",
                  "openai/gpt-5.1-codex-mini": "OpenAI: GPT-5.1-Codex-Mini (400,000 tokens)",
                  "openai/gpt-5.2": "OpenAI: GPT-5.2 (400,000 tokens)",
                  "openai/gpt-5.2-chat": "OpenAI: GPT-5.2 Chat (128,000 tokens)",
                  "openai/gpt-5.2-codex": "OpenAI: GPT-5.2-Codex (400,000 tokens)",
                  "openai/gpt-5.2-pro": "OpenAI: GPT-5.2 Pro (400,000 tokens)",
                  "openai/gpt-oss-120b": "OpenAI: gpt-oss-120b (131,072 tokens)",
                  "openai/gpt-oss-120b:exacto": "OpenAI: gpt-oss-120b (exacto) (131,072 tokens)",
                  "openai/gpt-oss-120b:free": "OpenAI: gpt-oss-120b (free) (131,072 tokens)",
                  "openai/gpt-oss-20b": "OpenAI: gpt-oss-20b (131,072 tokens)",
                  "openai/gpt-oss-20b:free": "OpenAI: gpt-oss-20b (free) (131,072 tokens)",
                  "openai/gpt-oss-safeguard-20b": "OpenAI: gpt-oss-safeguard-20b (131,072 tokens)",
                  "openai/o1": "OpenAI: o1 (200,000 tokens)",
                  "openai/o1-pro": "OpenAI: o1-pro (200,000 tokens)",
                  "openai/o3": "OpenAI: o3 (200,000 tokens)",
                  "openai/o3-deep-research": "OpenAI: o3 Deep Research (200,000 tokens)",
                  "openai/o3-mini": "OpenAI: o3 Mini (200,000 tokens)",
                  "openai/o3-mini-high": "OpenAI: o3 Mini High (200,000 tokens)",
                  "openai/o3-pro": "OpenAI: o3 Pro (200,000 tokens)",
                  "openai/o4-mini": "OpenAI: o4 Mini (200,000 tokens)",
                  "openai/o4-mini-deep-research": "OpenAI: o4 Mini Deep Research (200,000 tokens)",
                  "openai/o4-mini-high": "OpenAI: o4 Mini High (200,000 tokens)",
                  "opengvlab/internvl3-78b": "OpenGVLab: InternVL3 78B (32,768 tokens)",
                  "openrouter/auto": "Auto Router (2,000,000 tokens)",
                  "openrouter/bodybuilder": "Body Builder (beta) (128,000 tokens)",
                  "perplexity/sonar": "Perplexity: Sonar (127,072 tokens)",
                  "perplexity/sonar-deep-research": "Perplexity: Sonar Deep Research (128,000 tokens)",
                  "perplexity/sonar-pro": "Perplexity: Sonar Pro (200,000 tokens)",
                  "perplexity/sonar-pro-search": "Perplexity: Sonar Pro Search (200,000 tokens)",
                  "perplexity/sonar-reasoning-pro": "Perplexity: Sonar Reasoning Pro (128,000 tokens)",
                  "prime-intellect/intellect-3": "Prime Intellect: INTELLECT-3 (131,072 tokens)",
                  "qwen/qwen-2.5-72b-instruct": "Qwen2.5 72B Instruct (32,768 tokens)",
                  "qwen/qwen-2.5-7b-instruct": "Qwen: Qwen2.5 7B Instruct (32,768 tokens)",
                  "qwen/qwen-2.5-coder-32b-instruct": "Qwen2.5 Coder 32B Instruct (32,768 tokens)",
                  "qwen/qwen-2.5-vl-7b-instruct": "Qwen: Qwen2.5-VL 7B Instruct (32,768 tokens)",
                  "qwen/qwen-2.5-vl-7b-instruct:free": "Qwen: Qwen2.5-VL 7B Instruct (free) (32,768 tokens)",
                  "qwen/qwen-max": "Qwen: Qwen-Max  (32,768 tokens)",
                  "qwen/qwen-plus": "Qwen: Qwen-Plus (131,072 tokens)",
                  "qwen/qwen-plus-2025-07-28": "Qwen: Qwen Plus 0728 (1,000,000 tokens)",
                  "qwen/qwen-plus-2025-07-28:thinking": "Qwen: Qwen Plus 0728 (thinking) (1,000,000 tokens)",
                  "qwen/qwen-turbo": "Qwen: Qwen-Turbo (1,000,000 tokens)",
                  "qwen/qwen-vl-max": "Qwen: Qwen VL Max (131,072 tokens)",
                  "qwen/qwen-vl-plus": "Qwen: Qwen VL Plus (7,500 tokens)",
                  "qwen/qwen2.5-coder-7b-instruct": "Qwen: Qwen2.5 Coder 7B Instruct (32,768 tokens)",
                  "qwen/qwen2.5-vl-32b-instruct": "Qwen: Qwen2.5 VL 32B Instruct (16,384 tokens)",
                  "qwen/qwen2.5-vl-72b-instruct": "Qwen: Qwen2.5 VL 72B Instruct (32,768 tokens)",
                  "qwen/qwen3-14b": "Qwen: Qwen3 14B (40,960 tokens)",
                  "qwen/qwen3-235b-a22b": "Qwen: Qwen3 235B A22B (40,960 tokens)",
                  "qwen/qwen3-235b-a22b-2507": "Qwen: Qwen3 235B A22B Instruct 2507 (262,144 tokens)",
                  "qwen/qwen3-235b-a22b-thinking-2507": "Qwen: Qwen3 235B A22B Thinking 2507 (262,144 tokens)",
                  "qwen/qwen3-30b-a3b": "Qwen: Qwen3 30B A3B (40,960 tokens)",
                  "qwen/qwen3-30b-a3b-instruct-2507": "Qwen: Qwen3 30B A3B Instruct 2507 (262,144 tokens)",
                  "qwen/qwen3-30b-a3b-thinking-2507": "Qwen: Qwen3 30B A3B Thinking 2507 (32,768 tokens)",
                  "qwen/qwen3-32b": "Qwen: Qwen3 32B (40,960 tokens)",
                  "qwen/qwen3-4b:free": "Qwen: Qwen3 4B (free) (40,960 tokens)",
                  "qwen/qwen3-8b": "Qwen: Qwen3 8B (32,000 tokens)",
                  "qwen/qwen3-coder": "Qwen: Qwen3 Coder 480B A35B (262,144 tokens)",
                  "qwen/qwen3-coder-30b-a3b-instruct": "Qwen: Qwen3 Coder 30B A3B Instruct (160,000 tokens)",
                  "qwen/qwen3-coder-flash": "Qwen: Qwen3 Coder Flash (128,000 tokens)",
                  "qwen/qwen3-coder-plus": "Qwen: Qwen3 Coder Plus (128,000 tokens)",
                  "qwen/qwen3-coder:exacto": "Qwen: Qwen3 Coder 480B A35B (exacto) (262,144 tokens)",
                  "qwen/qwen3-coder:free": "Qwen: Qwen3 Coder 480B A35B (free) (262,000 tokens)",
                  "qwen/qwen3-max": "Qwen: Qwen3 Max (256,000 tokens)",
                  "qwen/qwen3-next-80b-a3b-instruct": "Qwen: Qwen3 Next 80B A3B Instruct (262,144 tokens)",
                  "qwen/qwen3-next-80b-a3b-instruct:free": "Qwen: Qwen3 Next 80B A3B Instruct (free) (262,144 tokens)",
                  "qwen/qwen3-next-80b-a3b-thinking": "Qwen: Qwen3 Next 80B A3B Thinking (128,000 tokens)",
                  "qwen/qwen3-vl-235b-a22b-instruct": "Qwen: Qwen3 VL 235B A22B Instruct (262,144 tokens)",
                  "qwen/qwen3-vl-235b-a22b-thinking": "Qwen: Qwen3 VL 235B A22B Thinking (131,072 tokens)",
                  "qwen/qwen3-vl-30b-a3b-instruct": "Qwen: Qwen3 VL 30B A3B Instruct (262,144 tokens)",
                  "qwen/qwen3-vl-30b-a3b-thinking": "Qwen: Qwen3 VL 30B A3B Thinking (131,072 tokens)",
                  "qwen/qwen3-vl-32b-instruct": "Qwen: Qwen3 VL 32B Instruct (262,144 tokens)",
                  "qwen/qwen3-vl-8b-instruct": "Qwen: Qwen3 VL 8B Instruct (131,072 tokens)",
                  "qwen/qwen3-vl-8b-thinking": "Qwen: Qwen3 VL 8B Thinking (256,000 tokens)",
                  "qwen/qwq-32b": "Qwen: QwQ 32B (32,768 tokens)",
                  "raifle/sorcererlm-8x22b": "SorcererLM 8x22B (16,000 tokens)",
                  "relace/relace-apply-3": "Relace: Relace Apply 3 (256,000 tokens)",
                  "relace/relace-search": "Relace: Relace Search (256,000 tokens)",
                  "sao10k/l3-euryale-70b": "Sao10k: Llama 3 Euryale 70B v2.1 (8,192 tokens)",
                  "sao10k/l3-lunaris-8b": "Sao10K: Llama 3 8B Lunaris (8,192 tokens)",
                  "sao10k/l3.1-70b-hanami-x1": "Sao10K: Llama 3.1 70B Hanami x1 (16,000 tokens)",
                  "sao10k/l3.1-euryale-70b": "Sao10K: Llama 3.1 Euryale 70B v2.2 (32,768 tokens)",
                  "sao10k/l3.3-euryale-70b": "Sao10K: Llama 3.3 Euryale 70B (131,072 tokens)",
                  "stepfun-ai/step3": "StepFun: Step3 (65,536 tokens)",
                  "switchpoint/router": "Switchpoint Router (131,072 tokens)",
                  "tencent/hunyuan-a13b-instruct": "Tencent: Hunyuan A13B Instruct (131,072 tokens)",
                  "thedrummer/cydonia-24b-v4.1": "TheDrummer: Cydonia 24B V4.1 (131,072 tokens)",
                  "thedrummer/rocinante-12b": "TheDrummer: Rocinante 12B (32,768 tokens)",
                  "thedrummer/skyfall-36b-v2": "TheDrummer: Skyfall 36B V2 (32,768 tokens)",
                  "thedrummer/unslopnemo-12b": "TheDrummer: UnslopNemo 12B (32,768 tokens)",
                  "tngtech/deepseek-r1t-chimera": "TNG: DeepSeek R1T Chimera (163,840 tokens)",
                  "tngtech/deepseek-r1t-chimera:free": "TNG: DeepSeek R1T Chimera (free) (163,840 tokens)",
                  "tngtech/deepseek-r1t2-chimera": "TNG: DeepSeek R1T2 Chimera (163,840 tokens)",
                  "tngtech/deepseek-r1t2-chimera:free": "TNG: DeepSeek R1T2 Chimera (free) (163,840 tokens)",
                  "tngtech/tng-r1t-chimera": "TNG: R1T Chimera (163,840 tokens)",
                  "tngtech/tng-r1t-chimera:free": "TNG: R1T Chimera (free) (163,840 tokens)",
                  "undi95/remm-slerp-l2-13b": "ReMM SLERP 13B (6,144 tokens)",
                  "x-ai/grok-3": "xAI: Grok 3 (131,072 tokens)",
                  "x-ai/grok-3-beta": "xAI: Grok 3 Beta (131,072 tokens)",
                  "x-ai/grok-3-mini": "xAI: Grok 3 Mini (131,072 tokens)",
                  "x-ai/grok-3-mini-beta": "xAI: Grok 3 Mini Beta (131,072 tokens)",
                  "x-ai/grok-4": "xAI: Grok 4 (256,000 tokens)",
                  "x-ai/grok-4-fast": "xAI: Grok 4 Fast (2,000,000 tokens)",
                  "x-ai/grok-4.1-fast": "xAI: Grok 4.1 Fast (2,000,000 tokens)",
                  "x-ai/grok-code-fast-1": "xAI: Grok Code Fast 1 (256,000 tokens)",
                  "xiaomi/mimo-v2-flash": "Xiaomi: MiMo-V2-Flash (262,144 tokens)",
                  "xiaomi/mimo-v2-flash:free": "Xiaomi: MiMo-V2-Flash (free) (262,144 tokens)",
                  "z-ai/glm-4-32b": "Z.AI: GLM 4 32B  (128,000 tokens)",
                  "z-ai/glm-4.5": "Z.AI: GLM 4.5 (131,072 tokens)",
                  "z-ai/glm-4.5-air": "Z.AI: GLM 4.5 Air (131,072 tokens)",
                  "z-ai/glm-4.5-air:free": "Z.AI: GLM 4.5 Air (free) (131,072 tokens)",
                  "z-ai/glm-4.5v": "Z.AI: GLM 4.5V (65,536 tokens)",
                  "z-ai/glm-4.6": "Z.AI: GLM 4.6 (202,752 tokens)",
                  "z-ai/glm-4.6:exacto": "Z.AI: GLM 4.6 (exacto) (204,800 tokens)",
                  "z-ai/glm-4.6v": "Z.AI: GLM 4.6V (131,072 tokens)",
                  "z-ai/glm-4.7": "Z.AI: GLM 4.7 (202,752 tokens)"
                },
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "x-ai/grok-4.1-fast"
              },
              "site_url": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Site URL",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "site_url",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are a research assistant for a weekly newsletter. Your job is to search Reddit for the top discussions, news, and controversies related to the Audience in the past week."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "override_skip": false,
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "track_in_telemetry": false,
                "type": "slider",
                "value": 0.7
              }
            },
            "tool_mode": false
          },
          "selected_output": "model_output",
          "showNode": true,
          "type": "OpenRouterComponent"
        },
        "dragging": false,
        "id": "OpenRouterComponent-a2foO",
        "measured": {
          "height": 483,
          "width": 320
        },
        "position": {
          "x": 391.890454583526,
          "y": -468.5829250997615
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ComposioRedditAPIComponent-Y34v6",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "display_name": "Reddit",
            "documentation": "https://docs.composio.dev",
            "edited": false,
            "field_order": [
              "entity_id",
              "api_key",
              "auth_mode",
              "auth_link",
              "client_id",
              "client_secret",
              "verification_token",
              "redirect_uri",
              "authorization_url",
              "token_url",
              "api_key_field",
              "generic_api_key",
              "token",
              "access_token",
              "refresh_token",
              "username",
              "password",
              "domain",
              "base_url",
              "bearer_token",
              "authorization_code",
              "scopes",
              "subdomain",
              "instance_url",
              "tenant_id",
              "action_button"
            ],
            "frozen": false,
            "icon": "Reddit",
            "last_updated": "2026-01-20T03:39:39.911Z",
            "legacy": false,
            "lf_version": "1.7.2",
            "metadata": {
              "code_hash": "a86794073c22",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.composio.reddit_composio.ComposioRedditAPIComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "input_types": [],
                "value": "f3b41284-a194-4443-91b5-8f1157eb27d3"
              },
              "_frontend_node_folder_id": {
                "input_types": [],
                "value": "5abc5f52-5ec3-4b44-b9b2-c1fb69504bf7"
              },
              "_type": "Component",
              "access_token": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Access Token",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "access_token",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "action_button": {
                "_input_type": "SortableListInput",
                "advanced": false,
                "display_name": "Action",
                "dynamic": false,
                "helper_text": "",
                "helper_text_metadata": {},
                "info": "",
                "input_types": [],
                "limit": 1,
                "name": "action_button",
                "options": [
                  {
                    "metadata": "REDDIT_CREATE_REDDIT_POST",
                    "name": "Create a Reddit post"
                  },
                  {
                    "metadata": "REDDIT_DELETE_REDDIT_COMMENT",
                    "name": "Delete Reddit comment"
                  },
                  {
                    "metadata": "REDDIT_DELETE_REDDIT_POST",
                    "name": "Delete a Reddit post"
                  },
                  {
                    "metadata": "REDDIT_EDIT_REDDIT_COMMENT_OR_POST",
                    "name": "Edit comment or post"
                  },
                  {
                    "metadata": "REDDIT_GET",
                    "name": "Get Reddit listing by sort"
                  },
                  {
                    "metadata": "REDDIT_GET_ME_PREFS",
                    "name": "Get user preferences"
                  },
                  {
                    "metadata": "REDDIT_GET_RANDOM",
                    "name": "Get random Reddit post"
                  },
                  {
                    "metadata": "REDDIT_GET_REDDIT_USER_ABOUT",
                    "name": "Get user information"
                  },
                  {
                    "metadata": "REDDIT_GET_R_SUBREDDIT_LINK_FLAIR_V2",
                    "name": "Get link flair templates v2"
                  },
                  {
                    "metadata": "REDDIT_GET_R_TOP",
                    "name": "Get top posts from subreddit"
                  },
                  {
                    "metadata": "REDDIT_GET_SUBREDDIT_RULES",
                    "name": "Get subreddit rules"
                  },
                  {
                    "metadata": "REDDIT_GET_SUBREDDITS_SEARCH",
                    "name": "Search subreddits"
                  },
                  {
                    "metadata": "REDDIT_GET_USER_FLAIR",
                    "name": "Get user flair"
                  },
                  {
                    "metadata": "REDDIT_GET_USERNAME_AVAILABLE",
                    "name": "Check username availability"
                  },
                  {
                    "metadata": "REDDIT_POST_REDDIT_COMMENT",
                    "name": "Post a comment"
                  },
                  {
                    "metadata": "REDDIT_RETRIEVE_POST_COMMENTS",
                    "name": "Retrieve Comments for a Post"
                  },
                  {
                    "metadata": "REDDIT_RETRIEVE_REDDIT_POST",
                    "name": "Retrieve posts from subreddit"
                  },
                  {
                    "metadata": "REDDIT_RETRIEVE_SPECIFIC_COMMENT",
                    "name": "Retrieve specific comment or post"
                  },
                  {
                    "metadata": "REDDIT_SEARCH_ACROSS_SUBREDDITS",
                    "name": "Search across subreddits"
                  }
                ],
                "override_skip": false,
                "placeholder": "Select action",
                "real_time_refresh": true,
                "required": false,
                "search_category": [],
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "sortableList",
                "value": "disabled"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Composio API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": true,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "api_key_field": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key_field",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "auth_link": {
                "_input_type": "AuthInput",
                "advanced": false,
                "auth_scheme": "OAUTH2",
                "auth_tooltip": "Disconnect",
                "connection_id": "ca_Y3fRUm-TGFRt",
                "display_name": "",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "name": "auth_link",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "auth",
                "value": "validated"
              },
              "auth_mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Auth Mode",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "name": "auth_mode",
                "options": [
                  "OAUTH2"
                ],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "tab",
                "value": "OAUTH2"
              },
              "authorization_code": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Authorization Code",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "authorization_code",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "authorization_url": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Authorization URL",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "authorization_url",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "base_url": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Base URL",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "base_url",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "bearer_token": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Bearer Token",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "bearer_token",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "client_id": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Client id",
                "dynamic": false,
                "info": "Client id of the app",
                "input_types": [],
                "load_from_db": false,
                "name": "client_id",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "client_secret": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Client secret",
                "dynamic": false,
                "info": "Client secret of the app",
                "input_types": [],
                "load_from_db": false,
                "name": "client_secret",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "type": "code",
                "value": "from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioRedditAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Reddit\"\n    icon = \"Reddit\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"reddit\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Reddit component.\"\"\"\n"
              },
              "create_auth_config": {
                "display_name": "",
                "helper_text": "",
                "input_types": [],
                "options": [
                  "create"
                ],
                "show": false,
                "value": ""
              },
              "domain": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Domain",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "domain",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "entity_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Entity ID",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "entity_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "default"
              },
              "generic_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "Enter API key on Composio page",
                "input_types": [],
                "load_from_db": false,
                "name": "generic_api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "instance_url": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Instance URL",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "instance_url",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "password": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Password",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "password",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "redirect_uri": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Redirect URI",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "redirect_uri",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "refresh_token": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Refresh Token",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "refresh_token",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "scopes": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Scopes",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "scopes",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "subdomain": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Subdomain",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "subdomain",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "tenant_id": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Tenant ID",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tenant_id",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "token": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Token",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "token",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "token_url": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Token URL",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "token_url",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "tool_mode": {
                "input_types": [],
                "value": true
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "tools",
                "value": [
                  {
                    "_uniqueId": "REDDIT_CREATE_REDDIT_POST_Create a Reddit post_0",
                    "args": {
                      "flair_id": {
                        "default": null,
                        "description": "ID of the post flair to apply. IMPORTANT: Some subreddits require post flair - if you get a flair required error, you must first fetch available flairs for the subreddit using the Reddit API endpoint GET /r/{subreddit}/api/link_flair_v2, then retry with a valid flair_id from that list.",
                        "examples": [
                          "a1b2c3d4-e5f6-7890-1234-567890abcdef"
                        ],
                        "title": "Flair Id",
                        "type": "string"
                      },
                      "kind": {
                        "default": null,
                        "description": "The type of the post. Use 'self' for a text-based post (when providing 'text') or 'link' for a post that links to an external URL (when providing 'url'). If omitted, it is automatically inferred: 'self' when 'text' is provided, 'link' when 'url' is provided.",
                        "examples": [
                          "self",
                          "link"
                        ],
                        "title": "Kind",
                        "type": "string"
                      },
                      "subreddit": {
                        "description": "The name of the subreddit (without the 'r/' prefix) where the post will be submitted. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "learnpython",
                          "AskReddit"
                        ],
                        "title": "Subreddit",
                        "type": "string"
                      },
                      "text": {
                        "default": null,
                        "description": "The markdown-formatted text content for a 'self' post. Required if `kind` is 'self'.",
                        "examples": [
                          "This is the body of my text post. It can include **markdown** formatting."
                        ],
                        "title": "Text",
                        "type": "string"
                      },
                      "title": {
                        "description": "The title of the post. Must be 300 characters or less. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "My New Project!",
                          "Interesting Article I Found"
                        ],
                        "title": "Title",
                        "type": "string"
                      },
                      "url": {
                        "default": null,
                        "description": "The URL for a 'link' post. Required if `kind` is 'link'.",
                        "examples": [
                          "https://www.example.com/news/article.html"
                        ],
                        "title": "Url",
                        "type": "string"
                      }
                    },
                    "description": "Creates a new text or link post on a specified, existing Reddit subreddit, optionally applying a flair.",
                    "display_description": "Creates a new text or link post on a specified, existing Reddit subreddit, optionally applying a flair.",
                    "display_name": "Create a Reddit post",
                    "name": "reddit_create_reddit_post",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_CREATE_REDDIT_POST"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_DELETE_REDDIT_COMMENT_Delete Reddit comment_1",
                    "args": {
                      "id": {
                        "description": "The full 'thing ID' (fullname, e.g., 't1_c0s4w1c') of the comment to delete; typically starts with 't1_'. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "t1_c0s4w1c"
                        ],
                        "title": "Id",
                        "type": "string"
                      }
                    },
                    "description": "Deletes a Reddit comment, identified by its fullname ID, if it was authored by the authenticated user.",
                    "display_description": "Deletes a Reddit comment, identified by its fullname ID, if it was authored by the authenticated user.",
                    "display_name": "Delete Reddit comment",
                    "name": "reddit_delete_reddit_comment",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_DELETE_REDDIT_COMMENT"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_DELETE_REDDIT_POST_Delete a Reddit post_2",
                    "args": {
                      "id": {
                        "description": "The full name (fullname) of the Reddit post to be deleted. This ID must start with 't3_' followed by the post's unique base36 identifier. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "t3_1abcdef",
                          "t3_gfedcba"
                        ],
                        "title": "Id",
                        "type": "string"
                      }
                    },
                    "description": "Permanently deletes a Reddit post by its ID, provided the authenticated user has deletion permissions for that post.",
                    "display_description": "Permanently deletes a Reddit post by its ID, provided the authenticated user has deletion permissions for that post.",
                    "display_name": "Delete a Reddit post",
                    "name": "reddit_delete_reddit_post",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_DELETE_REDDIT_POST"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_EDIT_REDDIT_COMMENT_OR_POST_Edit comment or post_3",
                    "args": {
                      "text": {
                        "description": "The new raw markdown text for the body of the comment or self-post. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "This is the *updated* content with **markdown** formatting."
                        ],
                        "title": "Text",
                        "type": "string"
                      },
                      "thing_id": {
                        "description": "The full name (fullname) of the comment or self-post to edit. This is a combination of a prefix (e.g., 't1_' for comment, 't3_' for post) and the item's ID. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "t1_c0c0c0c",
                          "t3_h0h0h0h"
                        ],
                        "title": "Thing Id",
                        "type": "string"
                      }
                    },
                    "description": "Edits the body text of the authenticated user's own existing comment or self-post on Reddit; cannot edit link posts or titles.",
                    "display_description": "Edits the body text of the authenticated user's own existing comment or self-post on Reddit; cannot edit link posts or titles.",
                    "display_name": "Edit comment or post",
                    "name": "reddit_edit_reddit_comment_or_post",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_EDIT_REDDIT_COMMENT_OR_POST"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_GET_Get Reddit listing by sort_4",
                    "args": {
                      "after": {
                        "default": null,
                        "description": "Fullname of a thing for pagination (loads posts after this item).",
                        "examples": [],
                        "title": "After",
                        "type": "string"
                      },
                      "before": {
                        "default": null,
                        "description": "Fullname of a thing for pagination (loads posts before this item).",
                        "examples": [],
                        "title": "Before",
                        "type": "string"
                      },
                      "count": {
                        "default": null,
                        "description": "A positive integer representing the number of items already seen (default: 0).",
                        "examples": [],
                        "title": "Count",
                        "type": "string"
                      },
                      "limit": {
                        "default": null,
                        "description": "The maximum number of items desired (default: 25, maximum: 100).",
                        "examples": [
                          25,
                          50,
                          100
                        ],
                        "title": "Limit",
                        "type": "string"
                      },
                      "show": {
                        "default": null,
                        "description": "The string 'all' to show all posts including filtered ones.",
                        "examples": [],
                        "title": "Show",
                        "type": "string"
                      },
                      "sort": {
                        "description": "The sorting method for results. Valid values: hot, new, top, rising, controversial, best. Note: 'random' is NOT supported here - use the GET_RANDOM action instead. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "hot",
                          "new",
                          "top",
                          "rising",
                          "controversial",
                          "best"
                        ],
                        "title": "Sort",
                        "type": "string"
                      },
                      "time_filter": {
                        "default": null,
                        "description": "Time filter for 'top' and 'controversial' sorts. Valid values: hour, day, week, month, year, all.",
                        "examples": [
                          "hour",
                          "day",
                          "week",
                          "month",
                          "year",
                          "all"
                        ],
                        "title": "Time Filter",
                        "type": "string"
                      }
                    },
                    "description": "Tool to retrieve a listing of Reddit posts sorted by the specified criteria (hot, new, top, etc.). Use when you need to get posts from the Reddit front page or all of Reddit with a specific sort order. Supports pagination and time filtering for top/controversial sorts.",
                    "display_description": "Tool to retrieve a listing of Reddit posts sorted by the specified criteria (hot, new, top, etc.). Use when you need to get posts from the Reddit front page or all of Reddit with a specific sort order. Supports pagination and time filtering for top/controversial sorts.",
                    "display_name": "Get Reddit listing by sort",
                    "name": "reddit_get",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_GET"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_GET_ME_PREFS_Get user preferences_5",
                    "args": {
                      "fields": {
                        "default": null,
                        "description": "A comma-separated list of preference fields to return. If not specified, all preference fields are returned. Supported fields include: threaded_messages, hide_downs, hide_ups, activity_relevant_ads, nightmode, compress, beta, media, media_preview, label_nsfw, over_18, search_include_over_18, hide_ads, email_messages, email_digests, monitor_mentions, hide_from_robots, profile_opt_out, public_votes, lang, theme_selector, min_comment_score, min_link_score, accept_pms, show_link_flair, show_trending, private_feeds, research, ignore_suggested_sort, domain_details, legacy_search, live_orangereds, highlight_controversial, no_profanity, email_unsubscribe_all, in_redesign_beta, allow_clicktracking, show_twitter, store_visits, threaded_modmail, enable_default_themes, geopopular, show_stylesheets, show_promote, organic, collapse_read_messages, show_flair, mark_messages_read, top_karma_subreddits, newwindow, video_autoplay, credit_autorenew, clickgadget, use_global_defaults, other_theme, num_comments, numsites, and g.",
                        "examples": [
                          "lang,theme_selector,nightmode",
                          "hide_ads,email_messages"
                        ],
                        "title": "Fields",
                        "type": "string"
                      }
                    },
                    "description": "Tool to retrieve preference settings of the logged in user. Use when you need to check user preferences or settings.",
                    "display_description": "Tool to retrieve preference settings of the logged in user. Use when you need to check user preferences or settings.",
                    "display_name": "Get user preferences",
                    "name": "reddit_get_me_prefs",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_GET_ME_PREFS"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_GET_RANDOM_Get random Reddit post_6",
                    "args": {
                      "subreddit": {
                        "default": null,
                        "description": "Name of the subreddit to get a random post from. If not specified, returns a random post from all of Reddit. Do not include 'r/' prefix.",
                        "examples": [
                          "AskReddit",
                          "technology",
                          "programming"
                        ],
                        "title": "Subreddit",
                        "type": "string"
                      }
                    },
                    "description": "Tool to retrieve a random public Reddit post from any subreddit. Use when you want to discover serendipitous content or need a random post for testing or entertainment purposes.",
                    "display_description": "Tool to retrieve a random public Reddit post from any subreddit. Use when you want to discover serendipitous content or need a random post for testing or entertainment purposes.",
                    "display_name": "Get random Reddit post",
                    "name": "reddit_get_random",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_GET_RANDOM"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_GET_REDDIT_USER_ABOUT_Get user information_7",
                    "args": {
                      "username": {
                        "description": "The name of an existing Reddit user to retrieve information about. Do not include 'u/' prefix. Use 'me' to get information about the currently authenticated user. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "spez",
                          "reddit",
                          "AutoModerator",
                          "me"
                        ],
                        "title": "Username",
                        "type": "string"
                      }
                    },
                    "description": "Retrieves information about a specified Reddit user account, including karma scores and gold status. Use when you need to get profile information for any public Reddit user.",
                    "display_description": "Retrieves information about a specified Reddit user account, including karma scores and gold status. Use when you need to get profile information for any public Reddit user.",
                    "display_name": "Get user information",
                    "name": "reddit_get_reddit_user_about",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_GET_REDDIT_USER_ABOUT"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_GET_R_SUBREDDIT_LINK_FLAIR_V2_Get link flair templates v2_8",
                    "args": {
                      "subreddit": {
                        "description": "The name of the subreddit to retrieve link flair templates from (e.g., 'test', 'python'). Do not include 'r/' prefix. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "test",
                          "python",
                          "AskReddit"
                        ],
                        "title": "Subreddit",
                        "type": "string"
                      }
                    },
                    "description": "Returns available link flair templates for posts in a subreddit. Use when you need to retrieve the list of link flair options that can be applied to posts, including enhanced v2 properties like richtext formatting and editable status.",
                    "display_description": "Returns available link flair templates for posts in a subreddit. Use when you need to retrieve the list of link flair options that can be applied to posts, including enhanced v2 properties like richtext formatting and editable status.",
                    "display_name": "Get link flair templates v2",
                    "name": "reddit_get_r_subreddit_link_flair_v2",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_GET_R_SUBREDDIT_LINK_FLAIR_V2"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_GET_R_TOP_Get top posts from subreddit_9",
                    "args": {
                      "after": {
                        "default": null,
                        "description": "Fullname of a thing to use as anchor for pagination. Returns results that occur after this fullname in the listing.",
                        "examples": [
                          "t3_abc123"
                        ],
                        "title": "After",
                        "type": "string"
                      },
                      "before": {
                        "default": null,
                        "description": "Fullname of a thing to use as anchor for pagination. Returns results that occur before this fullname in the listing.",
                        "examples": [
                          "t3_xyz789"
                        ],
                        "title": "Before",
                        "type": "string"
                      },
                      "count": {
                        "default": null,
                        "description": "Used by Reddit to number listings after the first page for pagination. Represents the number of items already seen.",
                        "examples": [
                          0,
                          25,
                          50
                        ],
                        "title": "Count",
                        "type": "string"
                      },
                      "limit": {
                        "default": 25,
                        "description": "Maximum number of top posts to return. Default is 25, maximum is 100. Please provide a value of type integer.",
                        "examples": [
                          10,
                          25,
                          50,
                          100
                        ],
                        "title": "Limit",
                        "type": "integer"
                      },
                      "show": {
                        "default": null,
                        "description": "Display filtering option. Use 'all' to return items that would normally be omitted (e.g., posts you have hidden).",
                        "examples": [
                          "all"
                        ],
                        "title": "Show",
                        "type": "string"
                      },
                      "sr_detail": {
                        "default": null,
                        "description": "Expand subreddits detail in response. Set to true to get more detailed subreddit information.",
                        "examples": [],
                        "title": "Sr Detail",
                        "type": "string"
                      },
                      "subreddit": {
                        "description": "The name of the subreddit to retrieve top posts from. Do not include 'r/' prefix. Subreddit names are case-insensitive but must be the actual subreddit name (not abbreviations or aliases). Use a subreddit search action first if unsure of the exact name. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "python",
                          "technology",
                          "programming",
                          "news"
                        ],
                        "title": "Subreddit",
                        "type": "string"
                      },
                      "t": {
                        "default": "all",
                        "description": "Time filter for ranking top posts. Specifies the time period for top posts: 'hour', 'day', 'week', 'month', 'year', or 'all' (default). Please provide a value of type string.",
                        "examples": [
                          "day",
                          "week",
                          "month",
                          "all"
                        ],
                        "title": "T",
                        "type": "string"
                      }
                    },
                    "description": "Tool to retrieve top-rated posts from a subreddit with time filters. Use when you need to find the most popular posts from a specific time period (hour, day, week, month, year, or all-time). Returns a paginated listing of posts ranked by score within the specified time frame.",
                    "display_description": "Tool to retrieve top-rated posts from a subreddit with time filters. Use when you need to find the most popular posts from a specific time period (hour, day, week, month, year, or all-time). Returns a paginated listing of posts ranked by score within the specified time frame.",
                    "display_name": "Get top posts from subreddit",
                    "name": "reddit_get_r_top",
                    "readonly": true,
                    "status": true,
                    "tags": [
                      "REDDIT_GET_R_TOP"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_GET_SUBREDDIT_RULES_Get subreddit rules_10",
                    "args": {
                      "raw_json": {
                        "default": true,
                        "description": "If True, prevents HTML encoding of special characters in rule descriptions. Recommended to set to True for cleaner text output. Please provide a value of type boolean.",
                        "examples": [],
                        "title": "Raw Json",
                        "type": "boolean"
                      },
                      "subreddit": {
                        "description": "Name of the subreddit (without 'r/' prefix) for which to retrieve posting rules. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "python",
                          "AskReddit",
                          "technology"
                        ],
                        "title": "Subreddit",
                        "type": "string"
                      }
                    },
                    "description": "Fetch the explicit posting rules for a subreddit to ensure compliance before posting or commenting. Use when you need to verify content meets community guidelines or explain subreddit requirements to users.",
                    "display_description": "Fetch the explicit posting rules for a subreddit to ensure compliance before posting or commenting. Use when you need to verify content meets community guidelines or explain subreddit requirements to users.",
                    "display_name": "Get subreddit rules",
                    "name": "reddit_get_subreddit_rules",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_GET_SUBREDDIT_RULES"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_GET_SUBREDDITS_SEARCH_Search subreddits_11",
                    "args": {
                      "after": {
                        "default": null,
                        "description": "Fullname of a thing - pagination cursor for the next page. Use the 'after' value from the previous response to get the next set of results.",
                        "examples": [
                          "t5_2qh1i"
                        ],
                        "title": "After",
                        "type": "string"
                      },
                      "before": {
                        "default": null,
                        "description": "Fullname of a thing - pagination cursor for the previous page. Use the 'before' value from the previous response to get the previous set of results.",
                        "examples": [
                          "t5_2qh1i"
                        ],
                        "title": "Before",
                        "type": "string"
                      },
                      "count": {
                        "default": null,
                        "description": "A positive integer (default: 0) representing the number of items already seen in previous pages. Used for pagination tracking.",
                        "examples": [
                          0,
                          10,
                          25
                        ],
                        "title": "Count",
                        "type": "string"
                      },
                      "limit": {
                        "default": 25,
                        "description": "The maximum number of subreddits to return. Default is 25. Maximum allowed value is 100. Please provide a value of type integer.",
                        "examples": [
                          10,
                          25,
                          50,
                          100
                        ],
                        "title": "Limit",
                        "type": "integer"
                      },
                      "q": {
                        "description": "A search query term to search subreddit titles and descriptions. Use specific keywords to find relevant subreddits. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "python",
                          "programming",
                          "artificial intelligence"
                        ],
                        "title": "Q",
                        "type": "string"
                      },
                      "show": {
                        "default": null,
                        "description": "The string 'all' to show all subreddits including those the user might have filtered.",
                        "examples": [
                          "all"
                        ],
                        "title": "Show",
                        "type": "string"
                      },
                      "show_users": {
                        "default": null,
                        "description": "Boolean value to include user results in the search. Set to true to include users matching the search query.",
                        "examples": [],
                        "title": "Show Users",
                        "type": "string"
                      },
                      "sort": {
                        "default": "relevance",
                        "description": "Sort order for the search results. 'relevance' sorts by relevance to the query (default). 'activity' sorts by subreddit activity. Please provide a value of type string.",
                        "examples": [
                          "relevance",
                          "activity"
                        ],
                        "title": "Sort",
                        "type": "string"
                      },
                      "sr_detail": {
                        "default": null,
                        "description": "Expand subreddits with additional details. Set to true to get more detailed information about each subreddit.",
                        "examples": [],
                        "title": "Sr Detail",
                        "type": "string"
                      }
                    },
                    "description": "Tool to search subreddits by title and description. Use when you need to find subreddits matching a specific topic or keyword. Returns a paginated listing of subreddits with their details including subscribers, descriptions, and other metadata.",
                    "display_description": "Tool to search subreddits by title and description. Use when you need to find subreddits matching a specific topic or keyword. Returns a paginated listing of subreddits with their details including subscribers, descriptions, and other metadata.",
                    "display_name": "Search subreddits",
                    "name": "reddit_get_subreddits_search",
                    "readonly": true,
                    "status": true,
                    "tags": [
                      "REDDIT_GET_SUBREDDITS_SEARCH"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_GET_USER_FLAIR_Get user flair_12",
                    "args": {
                      "subreddit": {
                        "description": "Name of the subreddit (e.g., 'pics', 'gaming') for which to retrieve user flair assignments. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "learnpython",
                          "datascience",
                          "announcements"
                        ],
                        "title": "Subreddit",
                        "type": "string"
                      }
                    },
                    "description": "Fetches the list of user flair assignments for a given subreddit. Returns paginated results with user flair details.",
                    "display_description": "Fetches the list of user flair assignments for a given subreddit. Returns paginated results with user flair details.",
                    "display_name": "Get user flair",
                    "name": "reddit_get_user_flair",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_GET_USER_FLAIR"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_GET_USERNAME_AVAILABLE_Check username availability_13",
                    "args": {
                      "user": {
                        "description": "The username to check for availability. Must be a valid, unused username string. Usernames are case-insensitive and must be between 3-20 characters. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "testuser123",
                          "example_username"
                        ],
                        "title": "User",
                        "type": "string"
                      }
                    },
                    "description": "Tool to check whether a username is available for registration on Reddit. Use when you need to verify if a username can be used to create a new account.",
                    "display_description": "Tool to check whether a username is available for registration on Reddit. Use when you need to verify if a username can be used to create a new account.",
                    "display_name": "Check username availability",
                    "name": "reddit_get_username_available",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_GET_USERNAME_AVAILABLE"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_POST_REDDIT_COMMENT_Post a comment_14",
                    "args": {
                      "text": {
                        "description": "REQUIRED. The raw Markdown text of the comment to be submitted. This field must be provided and cannot be empty. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "This is an insightful comment!",
                          "I agree completely."
                        ],
                        "title": "Text",
                        "type": "string"
                      },
                      "thing_id": {
                        "description": "REQUIRED. The ID of the parent post (link) or comment, prefixed with 't3_' for a post (e.g., 't3_10omtdx') or 't1_' for a comment (e.g., 't1_h2g9w8l'). This field must be provided. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "t3_10omtdx",
                          "t1_h2g9w8l"
                        ],
                        "title": "Thing Id",
                        "type": "string"
                      }
                    },
                    "description": "Posts a comment on Reddit, replying to an existing and accessible submission (post) or another comment.",
                    "display_description": "Posts a comment on Reddit, replying to an existing and accessible submission (post) or another comment.",
                    "display_name": "Post a comment",
                    "name": "reddit_post_reddit_comment",
                    "readonly": true,
                    "status": false,
                    "tags": [
                      "REDDIT_POST_REDDIT_COMMENT"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_RETRIEVE_POST_COMMENTS_Retrieve Comments for a Post_15",
                    "args": {
                      "article": {
                        "description": "Base-36 ID of the Reddit post (e.g., 'q5u7q5'), typically found in the post's URL and not including the 't3_' prefix. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "q5u7q5",
                          "13a9zao"
                        ],
                        "title": "Article",
                        "type": "string"
                      }
                    },
                    "description": "Retrieves all comments for a Reddit post given its article ID (which must be for an existing, public post); nested replies within comments are returned as raw dictionaries requiring parsing.",
                    "display_description": "Retrieves all comments for a Reddit post given its article ID (which must be for an existing, public post); nested replies within comments are returned as raw dictionaries requiring parsing.",
                    "display_name": "Retrieve Comments for a Post",
                    "name": "reddit_retrieve_post_comments",
                    "readonly": true,
                    "status": true,
                    "tags": [
                      "REDDIT_RETRIEVE_POST_COMMENTS"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_RETRIEVE_REDDIT_POST_Retrieve posts from subreddit_16",
                    "args": {
                      "size": {
                        "default": 5,
                        "description": "The maximum number of posts to return. Default is 5. Set to 0 to retrieve all available posts (or the maximum allowed by the Reddit API for a single request, typically up to 100 for this type of listing).",
                        "examples": [
                          "5",
                          "10",
                          "0",
                          "25"
                        ],
                        "title": "Size",
                        "type": "string"
                      },
                      "subreddit": {
                        "description": "The name of the subreddit from which to retrieve posts (e.g., 'popular', 'pics'). Do not include 'r/'. Subreddit names can only contain letters, numbers, and underscores, with no spaces or special characters. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "technology",
                          "python",
                          "news"
                        ],
                        "title": "Subreddit",
                        "type": "string"
                      }
                    },
                    "description": "Retrieves the current hot posts from a specified, publicly accessible subreddit.",
                    "display_description": "Retrieves the current hot posts from a specified, publicly accessible subreddit.",
                    "display_name": "Retrieve posts from subreddit",
                    "name": "reddit_retrieve_reddit_post",
                    "readonly": true,
                    "status": true,
                    "tags": [
                      "REDDIT_RETRIEVE_REDDIT_POST"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_RETRIEVE_SPECIFIC_COMMENT_Retrieve specific comment or post_17",
                    "args": {
                      "id": {
                        "description": "Reddit fullname identifier. Format: type prefix (t1_ for comments, t3_ for posts) followed by a base36 ID. Examples: 't1_abc123', 't3_1abc2de'. Note: Share URL tokens from reddit.com/r/.../s/... links are NOT valid fullnames and cannot be used directly. Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "t1_abc123",
                          "t3_1abc2de"
                        ],
                        "title": "Id",
                        "type": "string"
                      }
                    },
                    "description": "Retrieves detailed information for a specific Reddit comment or post using its fullname.",
                    "display_description": "Retrieves detailed information for a specific Reddit comment or post using its fullname.",
                    "display_name": "Retrieve specific comment or post",
                    "name": "reddit_retrieve_specific_comment",
                    "readonly": true,
                    "status": true,
                    "tags": [
                      "REDDIT_RETRIEVE_SPECIFIC_COMMENT"
                    ]
                  },
                  {
                    "_uniqueId": "REDDIT_SEARCH_ACROSS_SUBREDDITS_Search across subreddits_18",
                    "args": {
                      "limit": {
                        "default": 5,
                        "description": "The maximum number of search results to return. Default is 5. Maximum allowed value is 100. Please provide a value of type integer.",
                        "examples": [
                          "5",
                          "10",
                          "25"
                        ],
                        "title": "Limit",
                        "type": "integer"
                      },
                      "restrict_sr": {
                        "default": true,
                        "description": "If True (default), confines the search to posts and comments within subreddits. If False, the search scope is broader and may include matching subreddit names or other Reddit entities. Please provide a value of type boolean.",
                        "examples": [
                          true,
                          false
                        ],
                        "title": "Restrict Sr",
                        "type": "boolean"
                      },
                      "search_query": {
                        "description": "The search query string. Supports Reddit search operators: 'title:', 'author:', 'subreddit:', 'url:', 'site:', 'flair:', 'self:yes/no', 'nsfw:yes/no', and boolean operators (AND, OR, NOT). Raw URLs (starting with http:// or https://) are not allowed - use the 'url:' or 'site:' operators instead (e.g., 'url:example.com' to find posts linking to that domain). Please provide a value of type string. This parameter is required.",
                        "examples": [
                          "latest AI research",
                          "funny cat videos",
                          "url:youtube.com",
                          "site:imgur.com"
                        ],
                        "title": "Search Query",
                        "type": "string"
                      },
                      "sort": {
                        "default": "relevance",
                        "description": "The criterion for sorting search results. 'relevance' (default) sorts by relevance to the query. 'hot' sorts by trending posts with recent upvotes and activity. 'new' sorts by newest first. 'top' sorts by highest score (typically all-time). 'comments' sorts by the number of comments. Please provide a value of type string.",
                        "examples": [
                          "relevance",
                          "hot",
                          "new",
                          "top",
                          "comments"
                        ],
                        "title": "Sort",
                        "type": "string"
                      }
                    },
                    "description": "Searches Reddit for content (e.g., posts, comments) using a query, with results typically confined to subreddits unless `restrict_sr` is set to False.",
                    "display_description": "Searches Reddit for content (e.g., posts, comments) using a query, with results typically confined to subreddits unless `restrict_sr` is set to False.",
                    "display_name": "Search across subreddits",
                    "name": "reddit_search_across_subreddits",
                    "readonly": true,
                    "status": true,
                    "tags": [
                      "REDDIT_SEARCH_ACROSS_SUBREDDITS"
                    ]
                  }
                ]
              },
              "username": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Username",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "username",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "verification_token": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Verification Token",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "verification_token",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "ComposioRedditAPIComponent"
        },
        "dragging": false,
        "id": "ComposioRedditAPIComponent-Y34v6",
        "measured": {
          "height": 421,
          "width": 320
        },
        "position": {
          "x": 361.1113533081086,
          "y": 110.63174414400447
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-eoS4K",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/chat-input-and-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "context_id",
              "data_template",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.7.2",
            "metadata": {
              "code_hash": "8c87e536cca4",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "orjson",
                    "version": "3.10.15"
                  },
                  {
                    "name": "fastapi",
                    "version": "0.128.0"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.input_output.chat_output.ChatOutput"
            },
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean data before converting to string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.schema.properties import Source\nfrom lfx.template.field.base import Output\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/chat-input-and-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            advanced=True,\n            info=\"Whether to clean data before converting to string.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, _, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message) and not self.is_connected_to_chat_input():\n            message = self.input_value\n            # Update message properties\n            message.text = text\n            # Preserve existing session_id from the incoming message if it exists\n            existing_session_id = message.session_id\n        else:\n            message = Message(text=text)\n            existing_session_id = None\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        # Preserve session_id from incoming message, or use component/graph session_id\n        message.session_id = (\n            self.session_id or existing_session_id or (self.graph.session_id if hasattr(self, \"graph\") else None) or \"\"\n        )\n        message.context_id = self.context_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if message.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "id": "ChatOutput-eoS4K",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 1397.8825405568814,
          "y": 44.515540852664216
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatInput-HBnme",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "https://docs.langflow.org/chat-input-and-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "context_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.7.2",
            "metadata": {
              "code_hash": "7a26c54d89ed",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.input_output.chat.ChatInput"
            },
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from lfx.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom lfx.schema.message import Message\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/chat-input-and-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        # Ensure files is a list and filter out empty/None values\n        files = self.files if self.files else []\n        if files and not isinstance(files, list):\n            files = [files]\n        # Filter out None/empty values\n        files = [f for f in files if f is not None and f != \"\"]\n\n        session_id = self.session_id or self.graph.session_id or \"\"\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=session_id,\n            context_id=self.context_id,\n            files=files,\n        )\n        if session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "csv",
                  "json",
                  "pdf",
                  "txt",
                  "md",
                  "mdx",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "id": "ChatInput-HBnme",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 55.355217335287016,
          "y": -291.4344243895167
        },
        "selected": true,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 59.50013725710335,
      "y": 411.0182943860957,
      "zoom": 0.7858313061877731
    }
  },
  "description": "",
  "endpoint_name": null,
  "id": "f3b41284-a194-4443-91b5-8f1157eb27d3",
  "is_component": false,
  "last_tested_version": "1.7.2",
  "name": "BUTTON2BEEHIIV.GET_AUDIENCE_SNAPSHOT",
  "tags": []
}